{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# School shootings paper\n",
    "\n",
    "Some bibliography: https://www.mendeley.com/community/school-shootings-bib-(until-2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "import pandas as pd\n",
    "from numberAttacks import *\n",
    "from pylab import *\n",
    "#from cosas import *\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08 27 1990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1990</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Eldorado High</td>\n",
       "      <td>High</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gang-related</td>\n",
       "      <td>2519</td>\n",
       "      <td>38.7326807</td>\n",
       "      <td>-120.8118798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 09 1991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>James Monroe</td>\n",
       "      <td>High</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the victim challenged the perpetrator to a fig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.146905</td>\n",
       "      <td>-77.598189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04 23 1991</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Ralph J. Bunche Middle</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Compton</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perpetrator was aiming at another person and h...</td>\n",
       "      <td>1012</td>\n",
       "      <td>33.92167</td>\n",
       "      <td>-118.22814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11 01 1991</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>5</td>\n",
       "      <td>University of Iowa</td>\n",
       "      <td>College</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perpetrator was angry that his dissertation di...</td>\n",
       "      <td>27881</td>\n",
       "      <td>41.6616832</td>\n",
       "      <td>-91.5362795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 12 1992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Desert View</td>\n",
       "      <td>High</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586</td>\n",
       "      <td>33.5625415</td>\n",
       "      <td>-112.0687607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11 20 1992</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Edward Tilden</td>\n",
       "      <td>High</td>\n",
       "      <td>chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bystander to argument</td>\n",
       "      <td>possibly bystander to gang-related argument</td>\n",
       "      <td>1410</td>\n",
       "      <td>41.8075335</td>\n",
       "      <td>-87.6422731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11 16 1992</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>High</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shooter trying to steal athletic jacket</td>\n",
       "      <td>657</td>\n",
       "      <td>33.4906623</td>\n",
       "      <td>-86.9080477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01 13 1992</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Langham Creek</td>\n",
       "      <td>High</td>\n",
       "      <td>Houston</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Murder-suicide by estranged husband</td>\n",
       "      <td>2378</td>\n",
       "      <td>29.8791145</td>\n",
       "      <td>-95.6732795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05 01 1992</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>4</td>\n",
       "      <td>Lindhurst</td>\n",
       "      <td>High</td>\n",
       "      <td>Olivehurst</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perpetrator was angry over not graduating</td>\n",
       "      <td>1179</td>\n",
       "      <td>39.0843374</td>\n",
       "      <td>-121.5357962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10 06 1992</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>High</td>\n",
       "      <td>Houston</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1916</td>\n",
       "      <td>29.8160604</td>\n",
       "      <td>-95.5310535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12 14 1992</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Random</td>\n",
       "      <td>2</td>\n",
       "      <td>Simon's Rock College of Bard</td>\n",
       "      <td>College</td>\n",
       "      <td>Great Barrington</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perpetrator shot \"at anything that moved\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.20985</td>\n",
       "      <td>-73.386391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12 03 1992</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Woodson</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>539</td>\n",
       "      <td>41.8142004</td>\n",
       "      <td>-87.608661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>02 01 1993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Amityville</td>\n",
       "      <td>High</td>\n",
       "      <td>Amityville</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Due to prior dispute</td>\n",
       "      <td>716</td>\n",
       "      <td>40.6703784</td>\n",
       "      <td>-73.4117894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11 05 1993</td>\n",
       "      <td>1.342857</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Bay Springs</td>\n",
       "      <td>High</td>\n",
       "      <td>bay springs</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>377</td>\n",
       "      <td>31.9779313</td>\n",
       "      <td>-89.2783951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12 08 1993</td>\n",
       "      <td>1.685714</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Beach</td>\n",
       "      <td>High</td>\n",
       "      <td>savannah</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>possibly gang related</td>\n",
       "      <td>but not proven</td>\n",
       "      <td>1566</td>\n",
       "      <td>32.0533728</td>\n",
       "      <td>-81.116455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>05 21 1993</td>\n",
       "      <td>2.028571</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Boston</td>\n",
       "      <td>High</td>\n",
       "      <td>boston</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.3484309</td>\n",
       "      <td>-71.06894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>02 26 1993</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Century</td>\n",
       "      <td>High</td>\n",
       "      <td>santa ana</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>victim was not in a gang</td>\n",
       "      <td>but was targeted due to gang violence</td>\n",
       "      <td>2388</td>\n",
       "      <td>33.727796</td>\n",
       "      <td>-117.8495001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12 16 1993</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>High</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perpetrator left a grievance hearing</td>\n",
       "      <td>upset about complaint/file on his behavior</td>\n",
       "      <td>731</td>\n",
       "      <td>42.312898</td>\n",
       "      <td>-84.0059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>02 24 1993</td>\n",
       "      <td>3.057143</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>High</td>\n",
       "      <td>reseda</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2509</td>\n",
       "      <td>33.8441824</td>\n",
       "      <td>-118.1067328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01 18 1993</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>2</td>\n",
       "      <td>East Carter</td>\n",
       "      <td>High</td>\n",
       "      <td>Grayson</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hostage situation</td>\n",
       "      <td>killed teacher and custodian</td>\n",
       "      <td>angry at bad grade on report card</td>\n",
       "      <td>587</td>\n",
       "      <td>38.326259</td>\n",
       "      <td>-82.930504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01 21 1993</td>\n",
       "      <td>3.742857</td>\n",
       "      <td>23</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Fairfax</td>\n",
       "      <td>High</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2047</td>\n",
       "      <td>34.0827872</td>\n",
       "      <td>-118.3595219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>04 15 1993</td>\n",
       "      <td>4.085714</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Middle</td>\n",
       "      <td>acushnet</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>school nurse killed in hostage situation</td>\n",
       "      <td>360</td>\n",
       "      <td>41.7234365</td>\n",
       "      <td>-70.9058722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>04 03 1993</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>14</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Grant</td>\n",
       "      <td>High</td>\n",
       "      <td>sacramento</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>victims and friend walking past baseball field</td>\n",
       "      <td>shot by unknown perpetrator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6357374</td>\n",
       "      <td>-121.4349538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>04 16 1993</td>\n",
       "      <td>4.771429</td>\n",
       "      <td>24</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Grant</td>\n",
       "      <td>High</td>\n",
       "      <td>sacramento</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shot in head by stray bullet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6357374</td>\n",
       "      <td>-121.4349538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>03 18 1993</td>\n",
       "      <td>5.114286</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>High</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shot during argument with shooter over a girl ...</td>\n",
       "      <td>923</td>\n",
       "      <td>33.4654153</td>\n",
       "      <td>-82.3120681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08 31 1993</td>\n",
       "      <td>5.457143</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Harper</td>\n",
       "      <td>High</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>victim and shooter had been \"feuding\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.8304705</td>\n",
       "      <td>-83.9835031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>02 18 1993</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>25</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Kimball</td>\n",
       "      <td>High</td>\n",
       "      <td>dallas</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>victim shot by girlfriend's ex-boyfriend</td>\n",
       "      <td>1668</td>\n",
       "      <td>32.6992988</td>\n",
       "      <td>-96.8775028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>04 26 1993</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Millbrook</td>\n",
       "      <td>High</td>\n",
       "      <td>raleigh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dispute over alleged theft of a hat</td>\n",
       "      <td>victim may have been a bystander</td>\n",
       "      <td>2057</td>\n",
       "      <td>35.8657062</td>\n",
       "      <td>-78.6038915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11 04 1993</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>New Britain</td>\n",
       "      <td>High</td>\n",
       "      <td>new britain</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>masked gunman fired on victim</td>\n",
       "      <td>possibly gang related</td>\n",
       "      <td>1705</td>\n",
       "      <td>41.6506548</td>\n",
       "      <td>-72.7778752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>05 27 1993</td>\n",
       "      <td>6.828571</td>\n",
       "      <td>26</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Nicholls</td>\n",
       "      <td>High</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown cause of dispute</td>\n",
       "      <td>schoolyard scuffle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.7944154</td>\n",
       "      <td>-90.8015178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>02 02 2011</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>Louisiana Schnell Elementary School</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>placerville</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>disagreement between custodian perpetrator and...</td>\n",
       "      <td>perpetrator also thought he had been fired</td>\n",
       "      <td>424</td>\n",
       "      <td>38.7351808</td>\n",
       "      <td>-120.7768784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>01 05 2011</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>millard south</td>\n",
       "      <td>High</td>\n",
       "      <td>omaha</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2043</td>\n",
       "      <td>41.2041657</td>\n",
       "      <td>-96.1466863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>04 06 2011</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>southern union community college</td>\n",
       "      <td>College</td>\n",
       "      <td>opelika</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>domestic violence dispute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.1276199</td>\n",
       "      <td>-85.5716212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>12 08 2011</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Virginia Tech</td>\n",
       "      <td>College</td>\n",
       "      <td>blacksburg</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motive unknown</td>\n",
       "      <td>killed campus police officer</td>\n",
       "      <td>28650</td>\n",
       "      <td>37.2283333</td>\n",
       "      <td>-80.4180556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>03 31 2011</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>worthing high</td>\n",
       "      <td>High</td>\n",
       "      <td>houston</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>935</td>\n",
       "      <td>29.6574534</td>\n",
       "      <td>-95.366883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>02 06 2011</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>youngstown university</td>\n",
       "      <td>College</td>\n",
       "      <td>youngtown</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dispute at a party led to perpetrators being a...</td>\n",
       "      <td>they returned at sprayed bullets into the crowd</td>\n",
       "      <td>13698</td>\n",
       "      <td>41.1042248</td>\n",
       "      <td>-80.6470194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>02 27 2012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>3</td>\n",
       "      <td>Chardon High</td>\n",
       "      <td>High</td>\n",
       "      <td>Chardon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no clear motive</td>\n",
       "      <td>possibly for attention http://stateimpact.npr....</td>\n",
       "      <td>possibly due to being bullied http://www.huffi...</td>\n",
       "      <td>but possibly not bullied http://news.yahoo.com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.5914386</td>\n",
       "      <td>-81.200101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>03 06 2012</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>episcopal high</td>\n",
       "      <td>High</td>\n",
       "      <td>jacksonville</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fired teacher returned to campus and killed he...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.3071841</td>\n",
       "      <td>-81.6400945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>03 24 2012</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>mississippi state</td>\n",
       "      <td>College</td>\n",
       "      <td>starkville</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown motive</td>\n",
       "      <td>victim killed in dormatory room</td>\n",
       "      <td>21424</td>\n",
       "      <td>33.454844</td>\n",
       "      <td>-88.7886639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>04 02 2012</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>Random</td>\n",
       "      <td>7</td>\n",
       "      <td>Oikos</td>\n",
       "      <td>College</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.741001</td>\n",
       "      <td>-122.202003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>12 14 2012</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>Random</td>\n",
       "      <td>27</td>\n",
       "      <td>Sandy Hook Elementary</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Newtown</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>killed mother first</td>\n",
       "      <td>motive unclear</td>\n",
       "      <td>626</td>\n",
       "      <td>41.4200956</td>\n",
       "      <td>-73.2787274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>01 07 2013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>01 15 2013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>01 16 2013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>02 13 2013</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>San Leandro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>06 07 2013</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Random</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Santa Monica</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>06 20 2013</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>West Palm Beach</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>08 23 2013</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>Sardis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>09 21 2013</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Savannah</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>10 21 2013</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Sparks</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>12 13 2013</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>Arapahoe County</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>01 21 2014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>West Lafayette</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>01 24 2014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Orangeburg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>01 25 2014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>04 11 2014</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>04 21 2014</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Griffith</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>05 23 2014</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Random</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>06 05 2014</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>06 10 2014</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>Troutdale</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>10 24 2014</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Targeted</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>Marysville</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1   2     3     4         5   6   \\\n",
       "0    08 27 1990   1.000000   1   1.0  1990  Targeted   1   \n",
       "1    10 09 1991   1.000000   1   1.0  1991  Targeted   1   \n",
       "2    04 23 1991   5.000000   1   2.0  1991     Other   1   \n",
       "3    11 01 1991   9.000000   1   3.0  1991  Targeted   5   \n",
       "4    10 12 1992   1.000000   1   1.0  1992  Targeted   1   \n",
       "5    11 20 1992   2.500000  16   2.0  1992     Other   1   \n",
       "6    11 16 1992   4.000000   1   3.0  1992  Targeted   1   \n",
       "7    01 13 1992   5.500000  16   4.0  1992  Targeted   1   \n",
       "8    05 01 1992   7.000000   1   5.0  1992  Targeted   4   \n",
       "9    10 06 1992   8.500000  16   6.0  1992  Targeted   1   \n",
       "10   12 14 1992  10.000000   1   7.0  1992    Random   2   \n",
       "11   12 03 1992  11.500000  16   8.0  1992  Targeted   1   \n",
       "12   02 01 1993   1.000000   1   1.0  1993  Targeted   1   \n",
       "13   11 05 1993   1.342857  11   2.0  1993     Other   1   \n",
       "14   12 08 1993   1.685714  22   3.0  1993  Targeted   1   \n",
       "15   05 21 1993   2.028571   2   4.0  1993     Other   1   \n",
       "16   02 26 1993   2.371429  12   5.0  1993  Targeted   1   \n",
       "17   12 16 1993   2.714286  22   6.0  1993  Targeted   1   \n",
       "18   02 24 1993   3.057143   3   7.0  1993     Other   1   \n",
       "19   01 18 1993   3.400000  13   8.0  1993  Targeted   2   \n",
       "20   01 21 1993   3.742857  23   9.0  1993     Other   1   \n",
       "21   04 15 1993   4.085714   4  10.0  1993    Random   1   \n",
       "22   04 03 1993   4.428571  14  11.0  1993     Other   1   \n",
       "23   04 16 1993   4.771429  24  12.0  1993     Other   1   \n",
       "24   03 18 1993   5.114286   4  13.0  1993  Targeted   1   \n",
       "25   08 31 1993   5.457143  15  14.0  1993  Targeted   1   \n",
       "26   02 18 1993   5.800000  25  15.0  1993  Targeted   1   \n",
       "27   04 26 1993   6.142857   5  16.0  1993     Other   1   \n",
       "28   11 04 1993   6.485714  16  17.0  1993  Targeted   1   \n",
       "29   05 27 1993   6.828571  26  18.0  1993  Targeted   1   \n",
       "..          ...        ...  ..   ...   ...       ...  ..   \n",
       "204  02 02 2011   2.714286  22   2.0  2011  Targeted   1   \n",
       "205  01 05 2011   4.428571  14   3.0  2011  Targeted   1   \n",
       "206  04 06 2011   6.142857   5   4.0  2011  Targeted   1   \n",
       "207  12 08 2011   7.857143  27   5.0  2011     Other   1   \n",
       "208  03 31 2011   9.571429  18   6.0  2011  Targeted   1   \n",
       "209  02 06 2011  11.285714  10   7.0  2011    Random   1   \n",
       "210  02 27 2012   1.000000   1   1.0  2012  Targeted   3   \n",
       "211  03 06 2012   3.400000  13   2.0  2012  Targeted   1   \n",
       "212  03 24 2012   5.800000  25   3.0  2012  Targeted   1   \n",
       "213  04 02 2012   8.200000   7   4.0  2012    Random   7   \n",
       "214  12 14 2012  10.600000  19   5.0  2012    Random  27   \n",
       "215  01 07 2013   1.000000   7   NaN  2013  Targeted   1   \n",
       "216  01 15 2013   1.000000  15   NaN  2013  Targeted   3   \n",
       "217  01 16 2013   1.000000  16   NaN  2013     Other   1   \n",
       "218  02 13 2013   2.000000  13   NaN  2013  Targeted   1   \n",
       "219  06 07 2013   6.000000   7   NaN  2013    Random   4   \n",
       "220  06 20 2013   6.000000  20   NaN  2013  Targeted   2   \n",
       "221  08 23 2013   8.000000  23   NaN  2013  Targeted   1   \n",
       "222  09 21 2013   9.000000  21   NaN  2013  Targeted   1   \n",
       "223  10 21 2013  10.000000  21   NaN  2013    Random   1   \n",
       "224  12 13 2013  12.000000  13   NaN  2013     Other   1   \n",
       "225  01 21 2014   1.000000  21   NaN  2014  Targeted   1   \n",
       "226  01 24 2014   1.000000  24   NaN  2014  Targeted   1   \n",
       "227  01 25 2014   1.000000  25   NaN  2014  Targeted   1   \n",
       "228  04 11 2014   4.000000  11   NaN  2014    Random   1   \n",
       "229  04 21 2014   4.000000  21   NaN  2014  Targeted   1   \n",
       "230  05 23 2014   5.000000  23   NaN  2014    Random   6   \n",
       "231  06 05 2014   6.000000   5   NaN  2014    Random   1   \n",
       "232  06 10 2014   6.000000  10   NaN  2014     Other   1   \n",
       "233  10 24 2014  10.000000  24   NaN  2014  Targeted   3   \n",
       "\n",
       "                                      7           8                 9  ...  \\\n",
       "0                          Eldorado High        High         Las Vegas ...   \n",
       "1                           James Monroe        High             Bronx ...   \n",
       "2                 Ralph J. Bunche Middle      Middle           Compton ...   \n",
       "3                     University of Iowa     College         Iowa City ...   \n",
       "4                            Desert View        High            Tucson ...   \n",
       "5                          Edward Tilden        High           chicago ...   \n",
       "6                              Fairfield        High        Birmingham ...   \n",
       "7                          Langham Creek        High           Houston ...   \n",
       "8                              Lindhurst        High        Olivehurst ...   \n",
       "9                             Northbrook        High           Houston ...   \n",
       "10          Simon's Rock College of Bard     College  Great Barrington ...   \n",
       "11                               Woodson  Elementary           chicago ...   \n",
       "12                            Amityville        High        Amityville ...   \n",
       "13                           Bay Springs        High       bay springs ...   \n",
       "14                                 Beach        High          savannah ...   \n",
       "15                                Boston        High            boston ...   \n",
       "16                               Century        High         santa ana ...   \n",
       "17                               Chelsea        High           Chelsea ...   \n",
       "18                             Cleveland        High            reseda ...   \n",
       "19                           East Carter        High           Grayson ...   \n",
       "20                               Fairfax        High       los angeles ...   \n",
       "21                                  Ford      Middle          acushnet ...   \n",
       "22                                 Grant        High        sacramento ...   \n",
       "23                                 Grant        High        sacramento ...   \n",
       "24                                Harlem        High            Harlem ...   \n",
       "25                                Harper        High           atlanta ...   \n",
       "26                               Kimball        High            dallas ...   \n",
       "27                             Millbrook        High           raleigh ...   \n",
       "28                           New Britain        High       new britain ...   \n",
       "29                              Nicholls        High       New Orleans ...   \n",
       "..                                   ...         ...               ... ...   \n",
       "204  Louisiana Schnell Elementary School  Elementary       placerville ...   \n",
       "205                        millard south        High             omaha ...   \n",
       "206     southern union community college     College           opelika ...   \n",
       "207                        Virginia Tech     College        blacksburg ...   \n",
       "208                        worthing high        High           houston ...   \n",
       "209                youngstown university     College         youngtown ...   \n",
       "210                         Chardon High        High           Chardon ...   \n",
       "211                       episcopal high        High      jacksonville ...   \n",
       "212                    mississippi state     College        starkville ...   \n",
       "213                                Oikos     College           Oakland ...   \n",
       "214                Sandy Hook Elementary  Elementary           Newtown ...   \n",
       "215                                  NaN  Elementary        Fort Myers ...   \n",
       "216                                  NaN     College            Hazard ...   \n",
       "217                                  NaN     College           Chicago ...   \n",
       "218                                  NaN  Elementary       San Leandro ...   \n",
       "219                                  NaN     College      Santa Monica ...   \n",
       "220                                  NaN        High   West Palm Beach ...   \n",
       "221                                  NaN        High            Sardis ...   \n",
       "222                                  NaN     College          Savannah ...   \n",
       "223                                  NaN      Middle            Sparks ...   \n",
       "224                                  NaN        High   Arapahoe County ...   \n",
       "225                                  NaN     College    West Lafayette ...   \n",
       "226                                  NaN     College        Orangeburg ...   \n",
       "227                                  NaN     College       Los Angeles ...   \n",
       "228                                  NaN        High           Detroit ...   \n",
       "229                                  NaN  Elementary          Griffith ...   \n",
       "230                                  NaN     College     Santa Barbara ...   \n",
       "231                                  NaN     College           Seattle ...   \n",
       "232                                  NaN        High         Troutdale ...   \n",
       "233                                  NaN        High        Marysville ...   \n",
       "\n",
       "      15                                                 16  \\\n",
       "0    0.0                                       gang-related   \n",
       "1    0.0  the victim challenged the perpetrator to a fig...   \n",
       "2    0.0  perpetrator was aiming at another person and h...   \n",
       "3    1.0  perpetrator was angry that his dissertation di...   \n",
       "4    0.0                                                NaN   \n",
       "5    0.0                              Bystander to argument   \n",
       "6    0.0            Shooter trying to steal athletic jacket   \n",
       "7    1.0                Murder-suicide by estranged husband   \n",
       "8    0.0          perpetrator was angry over not graduating   \n",
       "9    0.0                                                NaN   \n",
       "10   0.0          perpetrator shot \"at anything that moved\"   \n",
       "11   0.0                                                NaN   \n",
       "12   0.0                               Due to prior dispute   \n",
       "13   0.0                                                NaN   \n",
       "14   0.0                              possibly gang related   \n",
       "15   0.0                                                NaN   \n",
       "16   0.0                           victim was not in a gang   \n",
       "17   0.0               perpetrator left a grievance hearing   \n",
       "18   0.0                                                NaN   \n",
       "19   0.0                                  hostage situation   \n",
       "20   0.0                                                NaN   \n",
       "21   0.0           school nurse killed in hostage situation   \n",
       "22   0.0     victims and friend walking past baseball field   \n",
       "23   0.0                       shot in head by stray bullet   \n",
       "24   0.0  shot during argument with shooter over a girl ...   \n",
       "25   0.0              victim and shooter had been \"feuding\"   \n",
       "26   0.0           victim shot by girlfriend's ex-boyfriend   \n",
       "27   0.0                dispute over alleged theft of a hat   \n",
       "28   0.0                      masked gunman fired on victim   \n",
       "29   0.0                           unknown cause of dispute   \n",
       "..   ...                                                ...   \n",
       "204  0.0  disagreement between custodian perpetrator and...   \n",
       "205  1.0                                                NaN   \n",
       "206  0.0                          domestic violence dispute   \n",
       "207  1.0                                     motive unknown   \n",
       "208  0.0                                                NaN   \n",
       "209  0.0  dispute at a party led to perpetrators being a...   \n",
       "210  0.0                                    no clear motive   \n",
       "211  0.0  fired teacher returned to campus and killed he...   \n",
       "212  0.0                                     unknown motive   \n",
       "213  0.0                                                NaN   \n",
       "214  1.0                                killed mother first   \n",
       "215  NaN                                                NaN   \n",
       "216  NaN                                                NaN   \n",
       "217  NaN                                                NaN   \n",
       "218  NaN                                                NaN   \n",
       "219  NaN                                                NaN   \n",
       "220  NaN                                                NaN   \n",
       "221  NaN                                                NaN   \n",
       "222  NaN                                                NaN   \n",
       "223  NaN                                                NaN   \n",
       "224  NaN                                                NaN   \n",
       "225  NaN                                                NaN   \n",
       "226  NaN                                                NaN   \n",
       "227  NaN                                                NaN   \n",
       "228  NaN                                                NaN   \n",
       "229  NaN                                                NaN   \n",
       "230  NaN                                                NaN   \n",
       "231  NaN                                                NaN   \n",
       "232  NaN                                                NaN   \n",
       "233  NaN                                                NaN   \n",
       "\n",
       "                                                    17  \\\n",
       "0                                                 2519   \n",
       "1                                                  NaN   \n",
       "2                                                 1012   \n",
       "3                                                27881   \n",
       "4                                                 1586   \n",
       "5          possibly bystander to gang-related argument   \n",
       "6                                                  657   \n",
       "7                                                 2378   \n",
       "8                                                 1179   \n",
       "9                                                 1916   \n",
       "10                                                 NaN   \n",
       "11                                                 539   \n",
       "12                                                 716   \n",
       "13                                                 377   \n",
       "14                                      but not proven   \n",
       "15                                                 NaN   \n",
       "16               but was targeted due to gang violence   \n",
       "17          upset about complaint/file on his behavior   \n",
       "18                                                2509   \n",
       "19                        killed teacher and custodian   \n",
       "20                                                2047   \n",
       "21                                                 360   \n",
       "22                         shot by unknown perpetrator   \n",
       "23                                                 NaN   \n",
       "24                                                 923   \n",
       "25                                                 NaN   \n",
       "26                                                1668   \n",
       "27                    victim may have been a bystander   \n",
       "28                               possibly gang related   \n",
       "29                                  schoolyard scuffle   \n",
       "..                                                 ...   \n",
       "204         perpetrator also thought he had been fired   \n",
       "205                                               2043   \n",
       "206                                                NaN   \n",
       "207                       killed campus police officer   \n",
       "208                                                935   \n",
       "209    they returned at sprayed bullets into the crowd   \n",
       "210  possibly for attention http://stateimpact.npr....   \n",
       "211                                                NaN   \n",
       "212                    victim killed in dormatory room   \n",
       "213                                                NaN   \n",
       "214                                     motive unclear   \n",
       "215                                                NaN   \n",
       "216                                                NaN   \n",
       "217                                                NaN   \n",
       "218                                                NaN   \n",
       "219                                                NaN   \n",
       "220                                                NaN   \n",
       "221                                                NaN   \n",
       "222                                                NaN   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "228                                                NaN   \n",
       "229                                                NaN   \n",
       "230                                                NaN   \n",
       "231                                                NaN   \n",
       "232                                                NaN   \n",
       "233                                                NaN   \n",
       "\n",
       "                                                    18  \\\n",
       "0                                           38.7326807   \n",
       "1                                            43.146905   \n",
       "2                                             33.92167   \n",
       "3                                           41.6616832   \n",
       "4                                           33.5625415   \n",
       "5                                                 1410   \n",
       "6                                           33.4906623   \n",
       "7                                           29.8791145   \n",
       "8                                           39.0843374   \n",
       "9                                           29.8160604   \n",
       "10                                            42.20985   \n",
       "11                                          41.8142004   \n",
       "12                                          40.6703784   \n",
       "13                                          31.9779313   \n",
       "14                                                1566   \n",
       "15                                          42.3484309   \n",
       "16                                                2388   \n",
       "17                                                 731   \n",
       "18                                          33.8441824   \n",
       "19                   angry at bad grade on report card   \n",
       "20                                          34.0827872   \n",
       "21                                          41.7234365   \n",
       "22                                                 NaN   \n",
       "23                                          38.6357374   \n",
       "24                                          33.4654153   \n",
       "25                                          30.8304705   \n",
       "26                                          32.6992988   \n",
       "27                                                2057   \n",
       "28                                                1705   \n",
       "29                                                 NaN   \n",
       "..                                                 ...   \n",
       "204                                                424   \n",
       "205                                         41.2041657   \n",
       "206                                         33.1276199   \n",
       "207                                              28650   \n",
       "208                                         29.6574534   \n",
       "209                                              13698   \n",
       "210  possibly due to being bullied http://www.huffi...   \n",
       "211                                         30.3071841   \n",
       "212                                              21424   \n",
       "213                                          37.741001   \n",
       "214                                                626   \n",
       "215                                                NaN   \n",
       "216                                                NaN   \n",
       "217                                                NaN   \n",
       "218                                                NaN   \n",
       "219                                                NaN   \n",
       "220                                                NaN   \n",
       "221                                                NaN   \n",
       "222                                                NaN   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "228                                                NaN   \n",
       "229                                                NaN   \n",
       "230                                                NaN   \n",
       "231                                                NaN   \n",
       "232                                                NaN   \n",
       "233                                                NaN   \n",
       "\n",
       "                                                    19            20  \\\n",
       "0                                         -120.8118798           NaN   \n",
       "1                                           -77.598189           NaN   \n",
       "2                                           -118.22814           NaN   \n",
       "3                                          -91.5362795           NaN   \n",
       "4                                         -112.0687607           NaN   \n",
       "5                                           41.8075335   -87.6422731   \n",
       "6                                          -86.9080477           NaN   \n",
       "7                                          -95.6732795           NaN   \n",
       "8                                         -121.5357962           NaN   \n",
       "9                                          -95.5310535           NaN   \n",
       "10                                          -73.386391           NaN   \n",
       "11                                          -87.608661           NaN   \n",
       "12                                         -73.4117894           NaN   \n",
       "13                                         -89.2783951           NaN   \n",
       "14                                          32.0533728    -81.116455   \n",
       "15                                           -71.06894           NaN   \n",
       "16                                           33.727796  -117.8495001   \n",
       "17                                           42.312898      -84.0059   \n",
       "18                                        -118.1067328           NaN   \n",
       "19                                                 587     38.326259   \n",
       "20                                        -118.3595219           NaN   \n",
       "21                                         -70.9058722           NaN   \n",
       "22                                          38.6357374  -121.4349538   \n",
       "23                                        -121.4349538           NaN   \n",
       "24                                         -82.3120681           NaN   \n",
       "25                                         -83.9835031           NaN   \n",
       "26                                         -96.8775028           NaN   \n",
       "27                                          35.8657062   -78.6038915   \n",
       "28                                          41.6506548   -72.7778752   \n",
       "29                                          29.7944154   -90.8015178   \n",
       "..                                                 ...           ...   \n",
       "204                                         38.7351808  -120.7768784   \n",
       "205                                        -96.1466863           NaN   \n",
       "206                                        -85.5716212           NaN   \n",
       "207                                         37.2283333   -80.4180556   \n",
       "208                                         -95.366883           NaN   \n",
       "209                                         41.1042248   -80.6470194   \n",
       "210  but possibly not bullied http://news.yahoo.com...           NaN   \n",
       "211                                        -81.6400945           NaN   \n",
       "212                                          33.454844   -88.7886639   \n",
       "213                                        -122.202003           NaN   \n",
       "214                                         41.4200956   -73.2787274   \n",
       "215                                                NaN           NaN   \n",
       "216                                                NaN           NaN   \n",
       "217                                                NaN           NaN   \n",
       "218                                                NaN           NaN   \n",
       "219                                                NaN           NaN   \n",
       "220                                                NaN           NaN   \n",
       "221                                                NaN           NaN   \n",
       "222                                                NaN           NaN   \n",
       "223                                                NaN           NaN   \n",
       "224                                                NaN           NaN   \n",
       "225                                                NaN           NaN   \n",
       "226                                                NaN           NaN   \n",
       "227                                                NaN           NaN   \n",
       "228                                                NaN           NaN   \n",
       "229                                                NaN           NaN   \n",
       "230                                                NaN           NaN   \n",
       "231                                                NaN           NaN   \n",
       "232                                                NaN           NaN   \n",
       "233                                                NaN           NaN   \n",
       "\n",
       "             21         22  23  24  \n",
       "0           NaN        NaN NaN NaN  \n",
       "1           NaN        NaN NaN NaN  \n",
       "2           NaN        NaN NaN NaN  \n",
       "3           NaN        NaN NaN NaN  \n",
       "4           NaN        NaN NaN NaN  \n",
       "5           NaN        NaN NaN NaN  \n",
       "6           NaN        NaN NaN NaN  \n",
       "7           NaN        NaN NaN NaN  \n",
       "8           NaN        NaN NaN NaN  \n",
       "9           NaN        NaN NaN NaN  \n",
       "10          NaN        NaN NaN NaN  \n",
       "11          NaN        NaN NaN NaN  \n",
       "12          NaN        NaN NaN NaN  \n",
       "13          NaN        NaN NaN NaN  \n",
       "14          NaN        NaN NaN NaN  \n",
       "15          NaN        NaN NaN NaN  \n",
       "16          NaN        NaN NaN NaN  \n",
       "17          NaN        NaN NaN NaN  \n",
       "18          NaN        NaN NaN NaN  \n",
       "19   -82.930504        NaN NaN NaN  \n",
       "20          NaN        NaN NaN NaN  \n",
       "21          NaN        NaN NaN NaN  \n",
       "22          NaN        NaN NaN NaN  \n",
       "23          NaN        NaN NaN NaN  \n",
       "24          NaN        NaN NaN NaN  \n",
       "25          NaN        NaN NaN NaN  \n",
       "26          NaN        NaN NaN NaN  \n",
       "27          NaN        NaN NaN NaN  \n",
       "28          NaN        NaN NaN NaN  \n",
       "29          NaN        NaN NaN NaN  \n",
       "..          ...        ...  ..  ..  \n",
       "204         NaN        NaN NaN NaN  \n",
       "205         NaN        NaN NaN NaN  \n",
       "206         NaN        NaN NaN NaN  \n",
       "207         NaN        NaN NaN NaN  \n",
       "208         NaN        NaN NaN NaN  \n",
       "209         NaN        NaN NaN NaN  \n",
       "210  41.5914386 -81.200101 NaN NaN  \n",
       "211         NaN        NaN NaN NaN  \n",
       "212         NaN        NaN NaN NaN  \n",
       "213         NaN        NaN NaN NaN  \n",
       "214         NaN        NaN NaN NaN  \n",
       "215         NaN        NaN NaN NaN  \n",
       "216         NaN        NaN NaN NaN  \n",
       "217         NaN        NaN NaN NaN  \n",
       "218         NaN        NaN NaN NaN  \n",
       "219         NaN        NaN NaN NaN  \n",
       "220         NaN        NaN NaN NaN  \n",
       "221         NaN        NaN NaN NaN  \n",
       "222         NaN        NaN NaN NaN  \n",
       "223         NaN        NaN NaN NaN  \n",
       "224         NaN        NaN NaN NaN  \n",
       "225         NaN        NaN NaN NaN  \n",
       "226         NaN        NaN NaN NaN  \n",
       "227         NaN        NaN NaN NaN  \n",
       "228         NaN        NaN NaN NaN  \n",
       "229         NaN        NaN NaN NaN  \n",
       "230         NaN        NaN NaN NaN  \n",
       "231         NaN        NaN NaN NaN  \n",
       "232         NaN        NaN NaN NaN  \n",
       "233         NaN        NaN NaN NaN  \n",
       "\n",
       "[234 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./data/ShootMiami2.csv\",sep=\";\",header=None)[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regetDataDaysMiami_v2(fname,state=0,type=0,time=0):\n",
    "    \n",
    "    f1 = open(fname)\n",
    "    #Add data to array\n",
    "    x = 1991\n",
    "    z = datetime(x,1,1)\n",
    "    j = []\n",
    "    countV = np.zeros(25)\n",
    "    countV2 = np.zeros(25)\n",
    "    count = 0\n",
    "    sizeEvent = []\n",
    "    sizeEvent2 = []\n",
    "    for line in f1:\n",
    "        a =line.split(';')\n",
    "        dat = datetime.strptime(a[0],\"%m %d %Y\")\n",
    "        try:\n",
    "\n",
    "            if state: condState = a[10] == state\n",
    "            else: condState = 1\n",
    "\n",
    "            if type == 'NCollege': condType = a[8] != type[1:]\n",
    "            elif type: condType = a[8] == type\n",
    "            else: condType = 1\n",
    "\n",
    "            if time: condTime = dat > datetime(year=time,month=1,day=1)\n",
    "            else: condTime = 1\n",
    "            if condState and condType and condTime:\n",
    "                countV[dat.year-1990] += int(a[6])\n",
    "                countV2[dat.year-1990] += 1\n",
    "\n",
    "                j.append(dat)\n",
    "                sizeEvent.append(int(a[6]))\n",
    "                sizeEvent2.append(int(a[6]))\n",
    "\n",
    "        except ValueError: pass\n",
    "\n",
    "\n",
    "    sizeEvent = [sizeV for (date, sizeV) in sorted(zip(j,sizeEvent))]\n",
    "    sizeEvent2 = [sizeV for (date, sizeV) in sorted(zip(j,sizeEvent2))]\n",
    "    j = sorted(j)\n",
    "    try: vtm = j.index(datetime.strptime(\"04 16 2007\",\"%m %d %Y\"))\n",
    "    except ValueError: vtm = 0\n",
    "\n",
    "    #print x, countV\n",
    "    ddd = j\n",
    "\n",
    "\n",
    "    a = [n.total_seconds()/60/60/24 for n in diff(j)]\n",
    "    daysBetweenKills = np.asarray(a)\n",
    "\n",
    "    daysBetweenKills[daysBetweenKills==0] += 0.1\n",
    "\n",
    "    #Separate attacks in the same day\n",
    "    while(np.any(np.diff(daysBetweenKills)==0)):\n",
    "        daysBetweenKills[np.concatenate([[False],np.diff(daysBetweenKills)==0])] += 0.1\n",
    "\n",
    "\n",
    "    daysBetweenAttacks = daysBetweenKills\n",
    "\n",
    "    return [ddd,np.asarray(sizeEvent),np.asarray(sizeEvent2),np.asarray(daysBetweenAttacks),countV,countV2,vtm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fig1A(fname):\n",
    "    fname = 'ShootMiami2.csv'\n",
    "    #fname = 'USAToday.csv'\n",
    "    fname = \"./data/\"+fname\n",
    "    if fname == 'ShootMiami2.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2(fname)\n",
    "    elif fname == \"USAToday.csv\": [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = studyUSAToday(fname)\n",
    "    print(sizeEvent)\n",
    "    [xCCDF,yCCDF,PDF] = get_CCDF(sizeEvent)\n",
    "\n",
    "\n",
    "    fig = figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    print(\"Med\", np.median(sizeEvent))\n",
    "\n",
    "    xmin = findXmin(sizeEvent)\n",
    "\n",
    "    plotGlobalPL(sizeEvent,xmin=xmin,ax=ax)\n",
    "    customaxis(ax,size=11,lw=2)\n",
    "    xlabel('Severity of Attacks (s)',fontsize = 12)\n",
    "    xlabel(r'$P(X>s)$',fontsize = 12)\n",
    "\n",
    "    savefig(fname+'PL_Dead_Miami_v2.pdf', bbox_inches='tight' ,dpi=100)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def testXx(fname = 'everytown.csv',state=0,type=0,time=0):\n",
    "\n",
    "    from datetime import datetime\n",
    "    fig = figure(figsize=(4.5,3))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    f1 = open(fname)\n",
    "    #Add data to array\n",
    "    x = 1991\n",
    "    j = []\n",
    "    pepe = dict()\n",
    "    n = []\n",
    "    for line in f1:\n",
    "        a =line.split(';')\n",
    "        dat = datetime.strptime(a[1],\"%m %d %Y\")\n",
    "\n",
    "        if dat == datetime.strptime(\"10 01 2007\",\"%m %d %Y\"): vtm = len(j)\n",
    "        try:\n",
    "            n.append((dat - datetime(2013,1,1)).total_seconds()/60./60./24.)\n",
    "            city= a[4] #3 state\n",
    "            t = city\n",
    "            if t == \"CA\": print dat\n",
    "\n",
    "            if pepe.get(t):\n",
    "                pepe[t].append(dat)\n",
    "            else:\n",
    "                pepe[t] = [dat]\n",
    "        except: pass\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(n)):\n",
    "        for j in range(i,len(n)):\n",
    "\n",
    "            temp.append([np.abs(n[i]-n[j])])\n",
    "    print np.median(temp)\n",
    "\n",
    "\n",
    "    print pepe\n",
    "    lab = []\n",
    "    pt = []\n",
    "    i = 0\n",
    "    for city in pepe:\n",
    "        if  len(pepe[city]) > 1:\n",
    "            i += 1\n",
    "            tac = pepe[city]\n",
    "            tac = [(_ - datetime(2013,1,1)).total_seconds()/60./60./24. for _ in tac]\n",
    "            print dcity, tac\n",
    "            pt += [np.median(np.diff(tac))]\n",
    "            lab.append(city)\n",
    "            for date in pepe[city]:\n",
    "                ax.plot(date,i,'.',ms=10,color='red',alpha=0.5)\n",
    "\n",
    "    customaxis(ax, c_right='none', c_top='none',lw=2, size=10, pad=8)\n",
    "    plt.yticks(range(1,1+len(lab)),lab)\n",
    "    plt.ylim((0.5,len(lab)+.5))\n",
    "    plt.xticks(rotation=30)\n",
    "    print np.median(pt)\n",
    "    savefig('CitiesCorr.pdf', bbox_inches='tight' ,dpi=10)\n",
    "    plt.show()\n",
    "    print len(pepe)\n",
    "\n",
    "def testX(fname = 'ShootMiami2.csv',state=0,type=0,time=0):\n",
    "    from datetime import datetime\n",
    "    f1 = open(fname)\n",
    "    #Add data to array\n",
    "    fig = figure(figsize=(4.5,3))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    pepe = dict()\n",
    "    for line in f1:\n",
    "        a =line.split(';')\n",
    "        dat = datetime.strptime(a[0],\"%m %d %Y\")\n",
    "        try:\n",
    "            city= a[10]\n",
    "            t = city\n",
    "            print t\n",
    "\n",
    "            if pepe.get(t):\n",
    "                pepe[t].append(dat)\n",
    "            else:\n",
    "                pepe[t] = [dat]\n",
    "        except: pass\n",
    "    print pepe\n",
    "    lab = []\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for city in ['CA', 'FL', 'GA', 'MI', 'WA','TN', 'PA',   'IL','AL','DC', 'TX',  'NY',  'OH']:\n",
    "        if  len(pepe[city]) > 5:\n",
    "            i += 1\n",
    "            tac = pepe[city]\n",
    "            tac = [(_ - datetime(1990,1,1)).total_seconds() for _ in tac]\n",
    "            print np.std(tac)\n",
    "            lab.append(city)\n",
    "            for date in pepe[city]:\n",
    "                ax.plot(date,i,'.',ms=10,color='red',alpha=0.5)\n",
    "\n",
    "    customaxis(ax, c_right='none', c_top='none',lw=2, size=10, pad=8)\n",
    "    plt.yticks(range(1,1+len(lab)),lab)\n",
    "    plt.ylim((0.5,len(lab)+.5))\n",
    "    plt.xticks(rotation=30)\n",
    "\n",
    "    savefig('StatsSchultzCorr.pdf', bbox_inches='tight' ,dpi=10)\n",
    "    print lab\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def studyTweets_v2(time=0):\n",
    "    import os\n",
    "    import pylab as plt\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "\n",
    "    listFiles = os.listdir(\"/home/j/Documents/Dropbox overflow/Twitter database/datav2/\")\n",
    "\n",
    "    d = dict()\n",
    "\n",
    "    for fileT in listFiles:\n",
    "        if \".tgz\" in fileT:\n",
    "            name = fileT[:-10]\n",
    "            name = \"20\" + name[-2:] +\"-\"+ name[3:5] + \"-\" + name[0:2]\n",
    "        elif \".gz\" in fileT:\n",
    "            name = fileT[:-15]\n",
    "        else: name = 0\n",
    "\n",
    "        if name:\n",
    "            with open(\"/home/j/Documents/Dropbox overflow/Twitter database/datav2/\"+fileT) as f:\n",
    "                t = np.asarray([int(_.strip()) for _ in f.readlines()])\n",
    "                if len(t) > 0:\n",
    "                    if d.has_key(name):\n",
    "                        d[name] += t\n",
    "                    else:\n",
    "                        d[name] = t\n",
    "\n",
    "\n",
    "    dates = []\n",
    "    tweetsAll = []\n",
    "    tweetsSS = []\n",
    "    tweetsMS = []\n",
    "    tweetsMM = []\n",
    "    tweetsS = []\n",
    "    for name in d:\n",
    "        if time:\n",
    "            if int(name[0:4]) > time:\n",
    "                dates.append(datetime (year=int(name[0:4]),month=int(name[5:7]),day=int(name[-2:])))\n",
    "\n",
    "                tweetsAll.append(float(d[name][0]))\n",
    "                tweetsSS.append(float(d[name][1]))\n",
    "                tweetsMS.append(float(d[name][2]))\n",
    "                tweetsMM.append(float(d[name][3]))\n",
    "                tweetsS.append(float(d[name][4]))\n",
    "        else:\n",
    "            dates.append(datetime (year=int(name[0:4]),month=int(name[5:7]),day=int(name[-2:])))\n",
    "\n",
    "            tweetsAll.append(float(d[name][0]))\n",
    "            tweetsSS.append(float(d[name][1]))\n",
    "            tweetsMS.append(float(d[name][2]))\n",
    "            tweetsMM.append(float(d[name][3]))\n",
    "            tweetsS.append(float(d[name][4]))\n",
    "\n",
    "\n",
    "    tweetsAll = np.asarray([tweet for (date,tweet) in sorted(zip(dates,tweetsAll))])\n",
    "    tweetsSS = np.asarray([tweet for (date,tweet) in sorted(zip(dates,tweetsSS))])\n",
    "    tweetsMS = np.asarray([tweet for (date,tweet) in sorted(zip(dates,tweetsMS))])\n",
    "    tweetsMM = np.asarray([tweet for (date,tweet) in sorted(zip(dates,tweetsMM))])\n",
    "    tweetsS = np.asarray([tweet for (date,tweet) in sorted(zip(dates,tweetsS))])\n",
    "    datesFinal = sorted(dates)\n",
    "    print np.sum(tweetsAll)\n",
    "    print np.sum(tweetsSS)\n",
    "    print np.sum(tweetsMM)\n",
    "    print np.sum(tweetsMS)\n",
    "    print np.sum(tweetsS)\n",
    "    return [datesFinal,tweetsS,tweetsSS,tweetsAll,tweetsMS,tweetsMM]\n",
    "\n",
    "def regetDataDaysEveryTown_v2(fname,state=0,type=0,time=0):\n",
    "    from datetime import datetime\n",
    "    f1 = open(fname)\n",
    "    #Add data to array\n",
    "    x = 1991\n",
    "    z = datetime(x,1,1)\n",
    "    j = []\n",
    "    countV = []\n",
    "    countV2 = np.zeros(25)\n",
    "    count = 0\n",
    "    sizeEvent = []\n",
    "    sizeEvent2 = []\n",
    "    vtm = 0\n",
    "    for line in f1:\n",
    "        a =line.split(';')\n",
    "        dat = datetime.strptime(a[1],\"%m %d %Y\")\n",
    "        if dat == datetime.strptime(\"10 01 2007\",\"%m %d %Y\"): vtm = len(j)\n",
    "        try:\n",
    "\n",
    "            #3 state\n",
    "            # 6 college\n",
    "            #7 gun fired\n",
    "            #8 injured\n",
    "            #9 death\n",
    "            #10 attemted suicide\n",
    "            #11 suicide\n",
    "\n",
    "            if state: condState = a[3] == state\n",
    "            else: condState = 1\n",
    "\n",
    "            if type == 'NCollege': condType = a[6] != type[1:]\n",
    "            elif type: condType = a[6] == type\n",
    "            else: condType = 1\n",
    "\n",
    "            if time: condTime = dat > datetime.strptime(\"1 1 2009\",\"%m %d %Y\")\n",
    "            else: condTime = 1\n",
    "            if condState and condType and condTime:\n",
    "\n",
    "                countV2[dat.year-1990] += 1\n",
    "                if a[6] =='College':\n",
    "                    countV.append(0)\n",
    "                else:\n",
    "                    countV.append(1)\n",
    "                j.append(dat)\n",
    "                sizeEvent.append(int(a[9]))\n",
    "                sizeEvent2.append(int(a[11]))\n",
    "\n",
    "        except ValueError: pass\n",
    "\n",
    "    #print x, countV\n",
    "    ddd = j\n",
    "\n",
    "\n",
    "    a = [n.total_seconds()/60/60/24 for n in diff(j)]\n",
    "    daysBetweenKills = np.asarray(a)\n",
    "\n",
    "    daysBetweenKills[daysBetweenKills==0] += 0.1\n",
    "\n",
    "    #Separate attacks in the same day\n",
    "    while(np.any(np.diff(daysBetweenKills)==0)):\n",
    "        daysBetweenKills[np.concatenate([[False],np.diff(daysBetweenKills)==0])] += 0.1\n",
    "\n",
    "\n",
    "    daysBetweenAttacks = daysBetweenKills\n",
    "\n",
    "    return [ddd,np.asarray(sizeEvent),np.asarray(sizeEvent2),np.asarray(daysBetweenAttacks),countV,countV2,vtm]\n",
    "\n",
    "\n",
    "\n",
    "def studyUSAToday(fname,state=0,type=0,time=0):\n",
    "    from datetime import datetime\n",
    "    f1 = open(fname)\n",
    "    #Add data to array\n",
    "    x = 1991\n",
    "    z = datetime(x,1,1)\n",
    "    j = []\n",
    "    countV = []\n",
    "    countV2 = np.zeros(25)\n",
    "    count = 0\n",
    "    sizeEvent = []\n",
    "    sizeEvent2 = []\n",
    "    vtm = 0\n",
    "    for lineNumber, line in enumerate(f1):\n",
    "        if lineNumber == 0: continue\n",
    "        a =line.split('\\t')\n",
    "        dat = datetime.strptime(a[0],\"%b %d, %Y\")\n",
    "        if dat == datetime.strptime(\"10 01 2007\",\"%m %d %Y\"): vtm = len(j)\n",
    "        try:\n",
    "            #3 state\n",
    "            # 6 college\n",
    "            #7 gun fired\n",
    "            #8 injured\n",
    "            #9 death\n",
    "            #10 attemted suicide\n",
    "            #11 suicide\n",
    "            if state:\n",
    "                condState = a[2] == state\n",
    "            else: condState = 1\n",
    "\n",
    "            #print(a[-2])\n",
    "            if a[-3] == \"Shooting\":\n",
    "                condType = 1\n",
    "            else:\n",
    "                condType = 0\n",
    "\n",
    "            if time: condTime = dat > datetime(year=time,month=1,day=1)\n",
    "            else: condTime = 1\n",
    "            if condState and condType and condTime:\n",
    "                #countV2[dat.year-1990] += 1\n",
    "                countV.append(1)\n",
    "                j.append(dat)\n",
    "                sizeEvent.append(int(a[-1]))\n",
    "                sizeEvent2.append(int(a[-1]))\n",
    "\n",
    "        except ValueError: pass\n",
    "\n",
    "    #print x, countV\n",
    "    ddd = j\n",
    "\n",
    "\n",
    "    a = [n.total_seconds()/60/60/24 for n in diff(j)]\n",
    "    daysBetweenKills = np.asarray(a)\n",
    "\n",
    "    daysBetweenKills[daysBetweenKills==0] += 0.1\n",
    "\n",
    "    #Separate attacks in the same day\n",
    "    while(np.any(np.diff(daysBetweenKills)==0)):\n",
    "        daysBetweenKills[np.concatenate([[False],np.diff(daysBetweenKills)==0])] += 0.1\n",
    "\n",
    "\n",
    "    daysBetweenAttacks = daysBetweenKills\n",
    "\n",
    "    return [ddd,np.asarray(sizeEvent),np.asarray(sizeEvent2),np.asarray(daysBetweenAttacks),countV,countV2,vtm]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def residualsMiami_v2():\n",
    "    from scipy.stats.stats import pearsonr\n",
    "    import scipy\n",
    "    name = ''\n",
    "    i=1\n",
    "\n",
    "    for fname in [ \"everytown.csv\"]:#['ShootMiami2.csv','everytown.csv']:#\n",
    "        if fname == 'ShootMiami2.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2(fname,time=2010)\n",
    "        elif fname == \"USAToday.csv\": [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = studyUSAToday(fname,time=2010)\n",
    "        else: [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2(fname)\n",
    "\n",
    "\n",
    "        print sizeEvent\n",
    "        print sizeEvent2\n",
    "        #sleep()\n",
    "        print pearsonr(sizeEvent,sizeEvent2)\n",
    "        x = np.median(sizeEvent)\n",
    "        print x\n",
    "        print np.mean(sizeEvent2[sizeEvent<=x]),np.std(sizeEvent2[sizeEvent<=x])\n",
    "        print np.mean(sizeEvent2[sizeEvent>x]),np.std(sizeEvent2[sizeEvent>x])\n",
    "\n",
    "\n",
    "        [xCCDF,yCCDF,PDF] = get_CCDF(sizeEvent)\n",
    "        #print len(sizeEvent)\n",
    "        dates =[0,len(sizeEvent)-1]\n",
    "        [_,_,_,_,_,x_p,y_p] = plotFrequency(dates, daysBetweenAttacks,1,1,1,name,vtm,ddd=ddd)\n",
    "\n",
    "        x_r = np.log10(np.arange(1,len(daysBetweenAttacks)+1))\n",
    "        y_r = np.log10((daysBetweenAttacks))\n",
    "        x = y_p-y_r\n",
    "\n",
    "        clf()\n",
    "        plt.show()\n",
    "        fig2 = figure(2,figsize=(4.5,3))\n",
    "        dist_name = 'norm'\n",
    "        axX = fig2.add_subplot(1,1,1)\n",
    "\n",
    "        h = 7\n",
    "        axX.hist(x,bins=np.linspace(-1.5,1.5,h),normed=1,edgecolor='white',facecolor='gray',alpha=0.5)\n",
    "\n",
    "        dist = getattr(scipy.stats, dist_name)\n",
    "        param = dist.fit(x)\n",
    "        x_pl = np.linspace(-1.5,1.5,100)\n",
    "        pdf_fitted = dist.pdf(x_pl, *param[:-2], loc=param[-2], scale=param[-1])\n",
    "        axX.plot(x_pl, pdf_fitted, linewidth=3,alpha=0.5,label='Normal Fit')\n",
    "        axX.legend()\n",
    "        axX.set_xlabel(r\"$\\sum{\\epsilon}$\")\n",
    "        axX.set_ylabel(\"Probability\")\n",
    "        customaxis(axX, c_right='none', c_top='none',lw=2, size=10, pad=8)\n",
    "        savefig(fname+'DistributionOutliers.pdf', bbox_inches='tight' ,dpi=10)\n",
    "        plt.show()\n",
    "        print(np.mean(x),np.std(x))\n",
    "        indexLate = np.nonzero(x<(np.mean(x)-1.*np.std(x)))[0]+1\n",
    "        indexEarly = np.nonzero(x>=(np.mean(x)+1.*np.std(x)))[0]+1\n",
    "        indexEarly = np.array(indexEarly,dtype=\"int\")\n",
    "        indexLate = np.array(indexLate,dtype=\"int\")\n",
    "        indLate = len(indexLate)\n",
    "        indEarly = len(indexEarly)\n",
    "\n",
    "\n",
    "        fig = figure(1, figsize=(9,6))\n",
    "        ax1 = fig.add_subplot(2,1,1)\n",
    "        [datesFinal,tweetsS,tweetsSS,tweetsAll,tweetsMS,tweetsMM] = studyTweets_v2(time=2009)\n",
    "\n",
    "        tweetsFinal = tweetsSS/tweetsAll\n",
    "        [datesFinal,tweetsFinal] = zip(*[(date,tweets)  for (date,tweets) in zip(datesFinal,tweetsFinal) if date>ddd[0]])\n",
    "        ax1.plot(datesFinal,1E6*np.asarray(tweetsFinal),'-',marker='.',linewidth=2,color='red',alpha=0.8)\n",
    "\n",
    "\n",
    "        ax1.set_ylabel('Number of tweets containing \\n\\\"school shooting\\\" per million',fontsize=11)\n",
    "        ax1.set_ylim([0,350])\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        tweetsBeforeAttackEarly = np.zeros(indEarly)\n",
    "        tweetsBeforeAttackLate = np.zeros(indLate)\n",
    "        tweetsNotBeforeAttack = np.zeros(len(ddd))\n",
    "\n",
    "        sizeBeforeAttackEarly = np.zeros(indEarly)\n",
    "        sizeBeforeAttackLate = np.zeros(indLate)\n",
    "        sizeNotBeforeAttack = np.zeros(len(ddd))\n",
    "\n",
    "        i = -1\n",
    "        for dateX in ddd:\n",
    "            i += 1\n",
    "            ax2.vlines(dateX,0,sizeEvent[i],color = 'gray',linewidth=2)\n",
    "            tweetsBefore = [tweets for (date,tweets) in zip(datesFinal,tweetsFinal) if date<dateX][-5:]\n",
    "            if len(tweetsBefore) == 0:\n",
    "                tweetsNotBeforeAttack[i] = np.NaN\n",
    "            else:\n",
    "                tweetsNotBeforeAttack[i] = np.max(tweetsBefore)\n",
    "            sizeNotBeforeAttack[i] = sizeEvent2[i]\n",
    "\n",
    "\n",
    "\n",
    "        i = -1\n",
    "        print(indexEarly)\n",
    "        for element in indexEarly:\n",
    "            #print ddd[element], element\n",
    "\n",
    "            i += 1\n",
    "            ax2.vlines(ddd[element],0,sizeEvent[element],color = (73./256, 142./256, 204./256),linewidth=3)\n",
    "            tweetsBefore = [tweets for (date,tweets) in zip(datesFinal,tweetsFinal) if date<ddd[element]][-5:]\n",
    "\n",
    "            tweetsBeforeAttackEarly[i] = np.max(tweetsBefore)\n",
    "            sizeBeforeAttackEarly[i] = sizeEvent2[element]\n",
    "\n",
    "\n",
    "        print(indexLate)\n",
    "        i = -1\n",
    "        for element in indexLate:\n",
    "            i += 1\n",
    "            ax2.vlines(ddd[element],0,sizeEvent[element],color = 'orange',linewidth=3)\n",
    "            tweetsBefore = [tweets for (date,tweets) in zip(datesFinal,tweetsFinal) if date<ddd[element]][-5:]\n",
    "\n",
    "            tweetsBeforeAttackLate[i] = np.max(tweetsBefore)\n",
    "            sizeBeforeAttackLate[i] = sizeEvent2[element]\n",
    "\n",
    "        print \"sizes\"\n",
    "        print sizeBeforeAttackLate\n",
    "        print sizeBeforeAttackEarly\n",
    "\n",
    "\n",
    "        ax2.set_ylabel('Size of Attack',fontsize=11)\n",
    "        ax1.set_xlabel('Time',fontsize=11)\n",
    "        customaxis(ax2, c_right='k', c_top='none',lw=2, size=10, pad=8)\n",
    "        customaxis(ax1, c_right='k', c_top='none',lw=2, size=10, pad=8)\n",
    "\n",
    "        ax2.set_ylim([0,4])\n",
    "        #ax1.set_xlim([datetime.datetime(2012,11,30),datetime.datetime(2013,3,30)])\n",
    "        #ax2.set_xlim([datetime.datetime(2012,11,30),datetime.datetime(2013,3,30)])\n",
    "        plt.clf()\n",
    "        ax5 = fig.add_subplot(2,1,2)\n",
    "        tweetsNotBeforeAttack *= 1E6\n",
    "        tweetsBeforeAttackLate *= 1E6\n",
    "        tweetsBeforeAttackEarly *= 1E6\n",
    "\n",
    "        print [np.median(tweetsNotBeforeAttack[~np.isnan(tweetsNotBeforeAttack)]),np.median(tweetsBeforeAttackEarly),\n",
    "                           np.median(tweetsBeforeAttackLate)]\n",
    "        print [np.mean(sizeNotBeforeAttack[~np.isnan(sizeNotBeforeAttack)]),np.mean(sizeBeforeAttackEarly),np.mean(sizeBeforeAttackLate)]\n",
    "        print sizeBeforeAttackEarly\n",
    "        print sizeBeforeAttackLate\n",
    "        color = ['gray',(73./256, 142./256, 204./256),'orange']\n",
    "        width = 0.4\n",
    "        ax5.bar([1,1.5,2],[np.median(tweetsNotBeforeAttack[~np.isnan(tweetsNotBeforeAttack)]),np.median(tweetsBeforeAttackEarly),\n",
    "                           np.median(tweetsBeforeAttackLate)],width=width,color=color)\n",
    "                            #yerr = [np.std(tweetsNotBeforeAttack[~np.isnan(tweetsNotBeforeAttack)]),np.std(tweetsBeforeAttackEarly)\n",
    "                            #    ,np.std(tweetsBeforeAttackLate)], width=width,color=color)\n",
    "        ax5.set_ylabel('Median number of tweets in the \\n5 days previous to the attack')\n",
    "\n",
    "\n",
    "        ax6 = ax5.twinx()\n",
    "        color = ['gray',(73./256, 142./256, 204./256),'orange']\n",
    "        ax6.bar([3,3.5,4],[np.mean(sizeNotBeforeAttack[~np.isnan(sizeNotBeforeAttack)]),np.mean(sizeBeforeAttackEarly),np.mean(sizeBeforeAttackLate)],width=width,color=color)\n",
    "                #yerr=[np.std(sizeNotBeforeAttack[~np.isnan(sizeNotBeforeAttack)]),np.std(sizeBeforeAttackEarly),np.std(sizeBeforeAttackLate)],width=width,color=color)\n",
    "        if fname == 'everytown.csv':\n",
    "            ax6.set_ylabel('Average suicide rate')\n",
    "        else:\n",
    "            ax6.set_ylabel('Average casualty number')\n",
    "\n",
    "        plt.xticks(np.asarray([1,1.5,2,3,3.5,4])+0.2,[\"All\",\"Early\",\"Late\",\"All\",\"Early\",\"Late\"])\n",
    "        customaxis(ax6, c_right='k', c_top='none',lw=2, size=10, pad=8)\n",
    "        customaxis(ax5, c_right='k', c_top='none',lw=2, size=10, pad=8)\n",
    "        savefig(fname+'StimelineOutliers.pdf', bbox_inches='tight' ,dpi=10)\n",
    "        show()\n",
    "\n",
    "\n",
    "def fig1BCD():\n",
    "    for fname in [\"USAToday.csv\"]:#['ShootMiami2.csv']:\n",
    "        for name in [0]:# ['NCollege','College',0]:\n",
    "            if fname == 'ShootMiami2.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2(fname,type=name)\n",
    "            elif fname == \"USAToday.csv\": [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = studyUSAToday(fname,type=name)\n",
    "            else: [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2(fname,type=name)\n",
    "            print(len(ddd))\n",
    "\n",
    "            if name == 'NCollege': name = 'K12'\n",
    "            if name == 0: name = 'All'\n",
    "\n",
    "            [xCCDF,yCCDF,PDF] = get_CCDF(sizeEvent)\n",
    "            fig = figure(1)\n",
    "\n",
    "            dates =[0,len(sizeEvent)-1]\n",
    "            fig = figure(figsize=(3.,3))\n",
    "            ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "            plotFrequency(dates, daysBetweenAttacks,1,1,1,'Mass',vtm,ax=ax1,ddd=ddd,allX=False)\n",
    "\n",
    "            #savefig('lowessMass.pdf', bbox_inches='tight' ,dpi=100)\n",
    "            xlabel(r'Log10 Attack number, $n$')\n",
    "            ylabel(r'Log10 Time between attacks $\\tau_n$')\n",
    "            title(name)\n",
    "            plt.gca().set_ylim(bottom=0)\n",
    "            savefig(str(name)+fname+'temp_Evo_Dead_Miami_v2.pdf', bbox_inches='tight' ,dpi=100)\n",
    "            show()\n",
    "            clf()\n",
    "\n",
    "def fig1EF(returnX = False,date=0):\n",
    "    for fname in ['ShootMiami2.csv']:#,\"USAToday.csv\"]:\n",
    "        for name in [0]:\n",
    "\n",
    "            if fname == \"USAToday.csv\": stateList = [  'Ariz.',  'Calif.',  'Fla.',  'Ill.', 'Ind.', 'Kan.', 'La.',   'Md.', 'Mich.',  'Mo.',        'N.C.', 'N.Y.', 'Ohio', 'Okla.', 'S.C.', 'Tenn.', 'Texas','Va.', 'W.Va.', 'Wash.', 'Wis.']\n",
    "            if fname == 'ShootMiami2.csv': stateList = [\"AL\",\"CA\",\"DC\",\"FL\",\"GA\",\"IL\",\"KY\",\"LA\",\"MI\",\"MN\",\"MS\",\"NC\",\"NY\",\"OH\",\"PA\",\"SC\",\"TN\",\"TX\",\"WA\"]\n",
    "            if fname == 'everytown.csv': stateList = [\"CA\",\"FL\",\"GA\",\"KY\",\"LA\",\"MI\",\"MN\",\"MS\",\"NC\",\"NY\",\"OH\",\"PA\",\"SC\",\"TN\",\"TX\",\"WA\"]\n",
    "            t2 = len(stateList)+1\n",
    "\n",
    "            tau1 = np.zeros(t2-1)\n",
    "            slope = np.zeros(t2-1)\n",
    "            t = np.ceil(np.sqrt(t2))\n",
    "            i = 0\n",
    "            j = -1\n",
    "            listSlopes =[]\n",
    "            listX = []\n",
    "            listStates = []\n",
    "            axis1 = np.ceil(np.sqrt(len(stateList)))\n",
    "            axis2 = np.ceil(np.sqrt(len(stateList)))\n",
    "            for state in stateList:\n",
    "                if fname == 'ShootMiami2.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2('ShootMiami2.csv',state=state,type=name,time=date)\n",
    "                elif fname == 'everytown.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2('everytown.csv',state=state,type=name)\n",
    "                elif fname == 'USAToday.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = studyUSAToday(\"USAToday.csv\",state=state)\n",
    "                j += 1\n",
    "                i += 1\n",
    "                print state,len(ddd)\n",
    "                dates =[0,len(sizeEvent)-1]\n",
    "                ## To study last 5 attacks\n",
    "                #daysBetweenAttacks = daysBetweenAttacks[max([-5,-len(daysBetweenAttacks)]):]\n",
    "                #dates = [0, len(daysBetweenAttacks)]\n",
    "\n",
    "                ## Normal\n",
    "                ax = subplot(axis1,axis2,i)\n",
    "                title(state)\n",
    "                [tau1[i-1],slope[i-1],listSlopesT,listXT,listStatesT,temp1,temp2] = plotFrequency(dates, daysBetweenAttacks,t,t,i,state,vtm,ax=ax,ddd=ddd,allX=False)\n",
    "\n",
    "                listSlopes = listSlopes + listSlopesT\n",
    "                listX = listX + listXT\n",
    "                listStates = listStates + listStatesT\n",
    "\n",
    "\n",
    "            i += 1\n",
    "            subplot(t,t,j)\n",
    "            hold(True)\n",
    "            #savefig(name+'K12toptopStates_Miami_AllStates.png', bbox_inches='tight' ,dpi=100)\n",
    "            #savefig('temp1.png', bbox_inches='tight' ,dpi=100)\n",
    "            fig = figure(figsize=(6.,3))\n",
    "            ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "            print tau1, slope\n",
    "            #stateList = [\"AL\",\"CAD\",\"CAE\",\"DC\",\"FL\",\"GA\",\"IL\",\"KY\",\"LA\",\"MI\",\"MN\",\"MS\",\"NC\",\"NY\",\"PA\",\"SC\",\"TN\",\"TX\",\"WA\"]\n",
    "            for i2 in range(len(tau1)):\n",
    "                #print st, i2\n",
    "                ax.plot(tau1[i2],slope[i2],'o')\n",
    "                ax.annotate(stateList[i2],(tau1[i2],slope[i2]+0.1))\n",
    "\n",
    "\n",
    "\n",
    "            slope2b, interceptb, r_valueb, p_value, std_err = linregress(tau1[~np.isnan(slope)],slope[~np.isnan(slope)])\n",
    "            print(\"MMMM\",std_err)\n",
    "            if returnX == True: return [slope2b, interceptb]\n",
    "\n",
    "\n",
    "            ax.plot(tau1[~np.isnan(slope)],interceptb+slope2b*tau1[~np.isnan(slope)],'green',linewidth=2)\n",
    "            ax.set_title([r'$R^b$= ',str(r_valueb**2)+' b = '+ str(slope2b)])\n",
    "            ax.set_xlabel(r'log $\\tau_{1}$',fontsize=11)\n",
    "            ax.set_ylabel(r'Learning rate b',fontsize=11)\n",
    "            #legend(stateList,loc='center left', bbox_to_anchor=(1, 0.5),ncol=3)\n",
    "            customaxis(ax,size=10,lw=2)\n",
    "            #savefig('SSstatesAllData_v2.pdf', bbox_inches='tight' ,dpi=100)\n",
    "            #show()\n",
    "            #clf()\n",
    "            \"\"\"\n",
    "            fig = figure(figsize=(6.,3))\n",
    "            ax = subplot(1,1,1)\n",
    "            listSlopes = (np.asarray(listSlopes))\n",
    "            listSlopes2 = list(listSlopes)\n",
    "            for i2 in listX:\n",
    "                i3 = listSlopes2.pop(0)\n",
    "                ax.scatter(i2,i3,s=20,facecolor =(0./256, 130./256, 130./256),edgecolor=(0./256, 130./256, 130./256),lw=0)\n",
    "                #annotate(listStates.pop(0),(i2,i3+0.1))\n",
    "\n",
    "            slope2, intercept, r_value, p_value, std_err = linregress(listX,listSlopes)\n",
    "            print \"slopes\",slope2, intercept\n",
    "            ax.plot(np.linspace(0,4,2),intercept+slope2*np.linspace(0,4,2),color=(0./256, 50./256, 130./256),linewidth=2)\n",
    "            title([''.join([r'$R^2$= ',str(r_value**2)]) ,''.join(['-b= ',str(slope2)])])\n",
    "            _L = []\n",
    "            listX = np.asarray(listX)\n",
    "            print listX\n",
    "            print listSlopes\n",
    "            print daysBetweenAttacks\n",
    "            print np.log10(daysBetweenAttacks)\n",
    "            t = np.linspace(min(listX),max(listX),6)\n",
    "            x =  sorted(zip(listX,listSlopes))\n",
    "            listX,listSlopes = zip(*x)\n",
    "\n",
    "            t = np.linspace(0,len(x),10)\n",
    "            _L1 = []\n",
    "            _L2 = []\n",
    "            for x in range(9):\n",
    "                _L1.append(np.mean(listX[int(t[x]):int(t[x+1])]))\n",
    "                _L2.append(np.mean(listSlopes[int(t[x]):int(t[x+1])]))\n",
    "\n",
    "            #plot(_L1,_L2,'o',color='red',linewidth=2)\n",
    "\n",
    "\n",
    "            xlines = [0,1,1.5,2,2.5,3,3.5,4]\n",
    "            ylines = [0,0.5,1,1.5,2,2.5,3,3.5,4]#sorted([8,4,2,0,-2,-4,-10])\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "        #customaxis(ax, c_right='none', c_top='none',lw=2, size=10, pad=8)\n",
    "        #xlim([0,4])\n",
    "\n",
    "        plt.xlim(1,4)\n",
    "        plt.ylim(-3.5,3)\n",
    "        savefig(fname+'SSInstRates_v2.pdf', bbox_inches='tight' ,dpi=100)\n",
    "        show()\n",
    "\n",
    "def fig1G():\n",
    "    [slope2b,interceptb] = fig1EF(returnX = True)\n",
    "\n",
    "    #1.83146071404 -5.08907637833 2.22318607529 -5.45669258405\n",
    "    stateList = [\"CA\",\"AL\",\"DC\",\"FL\",\"GA\",\"IL\",\"MI\",\"NC\",\"NY\",\"OH\",\"PA\",\"SC\",\"TN\",\"TX\",\"WA\"]\n",
    "\n",
    "    j = 0\n",
    "    slope2 = slope2b\n",
    "    intercept = interceptb\n",
    "    bestErr = 9999\n",
    "    out = -1\n",
    "    allC = 51\n",
    "    data = np.zeros([allC,allC])\n",
    "    for slope2 in [slope2]:#linspace(-2.,8,allC):\n",
    "        out += 1\n",
    "        inL = -1\n",
    "        for intercept in [intercept]:#linspace(-10,5,allC):\n",
    "            inL += 1\n",
    "            #108 0.308583133554 1.74832171778\n",
    "            #slope2 = 1.1377\n",
    "            #intercept = -2.5074\n",
    "            j = 0\n",
    "            #fig = figure(figsize=(1.5*12,1.5*10))\n",
    "            ## Prediction\n",
    "            totalAttacks= 0\n",
    "            err0T = []#np.empty(0)\n",
    "            err2Tx = []#np.empty(0)\n",
    "            err1T = []#np.empty(0)\n",
    "            err2T = []#np.empty(0)\n",
    "            err3T = []#np.empty(0)\n",
    "            err4T = []#np.empty(0)\n",
    "            err5T = []#np.empty(0)\n",
    "            err6T = []#np.empty(0)\n",
    "            tempErr = []\n",
    "            for state in stateList:\n",
    "                j+=1\n",
    "                [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2('ShootMiami2.csv',state=state)\n",
    "                totalAttacks += len(daysBetweenAttacks)\n",
    "\n",
    "                tau1 = np.log10(float(daysBetweenAttacks[0]))\n",
    "\n",
    "\n",
    "                daysTheoret = 10**(tau1)*(np.arange(1.,len(ddd),dtype='float')**-((intercept+slope2*tau1)))\n",
    "                #print state\n",
    "                #print (daysTheoret)\n",
    "                #print (daysBetweenAttacks)\n",
    "                daysTheorAdj = np.zeros(len(daysBetweenAttacks))\n",
    "                daysTheorAdjx = np.zeros(len(daysBetweenAttacks))\n",
    "                daysTheorAd2 = np.zeros(len(daysBetweenAttacks))\n",
    "                i = 0\n",
    "                daysTheorAdj[0] = daysBetweenAttacks[0]\n",
    "                daysTheorAdjx[0] = daysBetweenAttacks[0]\n",
    "                daysTheorAd2[0] = daysBetweenAttacks[0]\n",
    "                for times in daysBetweenAttacks[:-1]:\n",
    "                    i+=1\n",
    "                    daysTheorAdj[i] = float((times)*(((i+1.)/(i+2.))**-((intercept+slope2*tau1))))\n",
    "                    #daysTheorAdj[i] = float((times))\n",
    "                    #daysTheorAdjx[i] = float((times)\n",
    "                    daysTheorAd2[i] = np.median(daysBetweenAttacks[np.max([0,i-3]):i])#float((times)*(2.**-((intercept+slope2*np.log10(times)))))\n",
    "\n",
    "\n",
    "\n",
    "                #print daysTheorAdj\n",
    "                #print daysTheorAd2\n",
    "                daysTheoret2 = np.copy(daysTheoret)\n",
    "\n",
    "                for i in range(len(daysBetweenAttacks)-1):\n",
    "                    daysTheoret2[i+1] -= daysTheoret[i] - daysBetweenAttacks[i]\n",
    "\n",
    "\n",
    "                daysTheorLinRegg = np.copy(daysBetweenAttacks)\n",
    "                daysTheorLinReggSemiLog = np.copy(daysBetweenAttacks)\n",
    "                daysTheorLinReggSemiLog2 = np.copy(daysBetweenAttacks)\n",
    "\n",
    "\n",
    "                for i in range(len(daysBetweenAttacks)-2):\n",
    "                    #linear regression,\n",
    "                    slope2_t, intercept_t, r_value, p_value, std_err = linregress([1.,2.],daysBetweenAttacks[i:i+2])\n",
    "                    daysTheorLinRegg[i+2] = intercept_t+slope2_t*3.\n",
    "\n",
    "                    slope2_t, intercept_t, r_value, p_value, std_err = linregress(np.log10([1.,2.]),daysBetweenAttacks[i:i+2])\n",
    "                    daysTheorLinReggSemiLog[i+2] = intercept_t+slope2_t*np.log10(3.)\n",
    "\n",
    "                    slope2_t, intercept_t, r_value, p_value, std_err = linregress([1.,2.],np.log10(daysBetweenAttacks[i:i+2]))\n",
    "                    daysTheorLinReggSemiLog2[i+2] = 10**(intercept_t+slope2_t*3.)\n",
    "\n",
    "                err0 = (daysBetweenAttacks - daysTheoret2)/daysBetweenAttacks\n",
    "                err2x = (daysBetweenAttacks - daysTheorAdjx)/daysBetweenAttacks\n",
    "                err1 = (daysBetweenAttacks - daysTheoret)/daysBetweenAttacks\n",
    "\n",
    "\n",
    "                err2 = (daysBetweenAttacks - daysTheorAdj)/daysBetweenAttacks\n",
    "\n",
    "                err3 = (daysBetweenAttacks - daysTheorAd2)/daysBetweenAttacks\n",
    "                err4 = (daysBetweenAttacks - daysTheorLinRegg)/daysBetweenAttacks\n",
    "                err5 = (daysBetweenAttacks - daysTheorLinReggSemiLog)/daysBetweenAttacks\n",
    "                err6 = (daysBetweenAttacks - daysTheorLinReggSemiLog2)/daysBetweenAttacks\n",
    "                subplot(4,5,j)\n",
    "\n",
    "                err0T.append(np.median(np.abs(err0[1:])))# = np.concatenate([err0T,np.abs(err0[1:])])\n",
    "                err2Tx.append(np.median(np.abs(err2x[1:])))# = np.concatenate([err0T,np.abs(err0[1:])])\n",
    "                #print \"ererer\", err0T,err0[1:]\n",
    "                err1T.append(np.median(np.abs(err1[1:])))# = np.concatenate([err1T,np.abs(err1[1:])])\n",
    "                err2T.append(np.median(np.abs(err2[1:])))# = np.concatenate([err2T,np.abs(err2[1:])])\n",
    "                err3T.append(np.median(np.abs(err3[1:])))# = np.concatenate([err3T,np.abs(err3[1:])])\n",
    "                err4T.append(np.median(np.abs(err4[2:])))# = np.concatenate([err4T,np.abs(err4[2:])])\n",
    "                err5T.append(np.median(np.abs(err5[2:])))# = np.concatenate([err5T,np.abs(err5[2:])])\n",
    "                err6T.append(np.median(np.abs(err6[2:])))# = np.concatenate([err6T,np.abs(err6[2:])])\n",
    "                print state, np.round(err3[1:])\n",
    "\n",
    "\n",
    "                hold(True)\n",
    "                #plot(range(1,len(daysBetweenAttacks)),err0[1:],'o-',color='orange')\n",
    "                #plot(range(1,len(daysBetweenAttacks)),err1[1:],'o-',color='red')\n",
    "                #plot(range(1,len(daysBetweenAttacks)),err2[1:],'o-',color='blue')\n",
    "                #plot(range(1,len(daysBetweenAttacks)),err3[1:],'o-',color='green')\n",
    "                #plot(range(2,len(daysBetweenAttacks)),err4[2:],'o-',color='cyan')\n",
    "                #plot(range(2,len(daysBetweenAttacks)),err5[2:],'o-',color='cyan')\n",
    "                #plot(range(2,len(daysBetweenAttacks)),err6[2:],'o-',color='black')\n",
    "                #plot(range(len(daysBetweenAttacks)),np.zeros(len(daysBetweenAttacks)))\n",
    "                ylim([-2,2])\n",
    "                #ylim([min(np.concatenate([err4,err5])),max(np.concatenate([err4,err5]))])\n",
    "                title(state+str(np.median(np.abs(err3))))\n",
    "\n",
    "                if state == stateList[-1]:\n",
    "                    legend(['b) Same b, corrected','c) Same b, each attach','d) New b after each tau','f) Exponential interpolation'], loc='center left', bbox_to_anchor=(1, 0.5),ncol=1)\n",
    "                    #red. Same b, if an attack happens before it should it's added to the next one\n",
    "                    #blue. Same b, next attack calculated after each attack\n",
    "                    #green. New b after each attack\n",
    "                    #magenta. Linear regression in semilog plot (needs 3 points)\n",
    "\n",
    "            data[out,inL] = int(np.median(err3T))\n",
    "            #Predict\n",
    "            if int(np.median(err3T)) < bestErr or bestErr == 9999:\n",
    "                bestErr = int(np.median(err3T))\n",
    "                bestS = slope2\n",
    "                bestI = intercept\n",
    "            print out, inL, bestErr, bestS, bestI\n",
    "\n",
    "    print \"aaa\"\n",
    "    print err2Tx\n",
    "    print err2T\n",
    "    data = data.T\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    data[data>300] = 300\n",
    "    imshow(data, interpolation='none')\n",
    "    colorbar()\n",
    "    ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "    #ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    ax.set_xticklabels(linspace(-2,8,allC), minor=False,rotation=45)\n",
    "    ax.set_yticklabels(linspace(-10,5,allC), minor=False)\n",
    "\n",
    "    savefig('predictionBruteForce0.pdf', bbox_inches='tight' ,dpi=100)\n",
    "    \"\"\"\n",
    "    err0T = 100*np.asarray(err0T)\n",
    "    err1T = 100*np.asarray(err1T)\n",
    "    err2T = 100*np.asarray(err2T)\n",
    "    err2Tx = 100*np.asarray(err2Tx)\n",
    "    err3T = 100*np.asarray(err3T)\n",
    "    err5T = 100*np.asarray(err5T)\n",
    "    err6T = 100*np.asarray(err6T)\n",
    "\n",
    "    print bestErr, bestS, bestI\n",
    "    tempErr = np.asarray(tempErr)\n",
    "    print np.mean(tempErr), np.median(tempErr)\n",
    "    suptitle('b =' + str(int(np.median(err0T)))+'. c =' + str(int(np.median(err1T)))+'. d =' + str(int(np.median(err3T)))+'. f =' + str(int(np.median(err5T))))\n",
    "    print  (np.median(err0T)),(np.median(err1T)),(np.median(err2T)),(np.median(err3T)),(np.median(err4T)),(np.median(err5T)),(np.median(err6T))\n",
    "    print  (np.mean(err0T)),(np.mean(err1T)),(np.mean(err2T)),(np.mean(err3T)),(np.mean(err4T)),(np.mean(err5T)),(np.mean(err6T))\n",
    "    #plt.show()\n",
    "    #savefig('predictionColl2.pdf', bbox_inches='tight' ,dpi=100)\n",
    "    if int(np.median(err2T)) < bestErr:\n",
    "        bestErr = int(np.median(err2T))\n",
    "    show()\n",
    "    clf()\n",
    "    figure(figsize=(3,3))\n",
    "    ax = subplot(1,1,1)\n",
    "    import scipy\n",
    "    x = err2T\n",
    "    y = err3T\n",
    "    print(\"Mann-Whitney U test.\", scipy.stats.mannwhitneyu(x,y,use_continuity=True)[1]*2)\n",
    "    print(scipy.stats.levene(x,y)[1])\n",
    "\n",
    "    bar([0.1,0.5,0.9,1.4],[np.median(err2T),np.median(err3T),np.median(err5T),np.median(err6T)],0.35,\n",
    "        yerr=[[0,0,0,0],[np.std(err2T),np.std(err3T),np.std(err5T),np.std(err6T)]],color=[(73./256, 142./256, 204./256),(241./256, 98./256, 67./256),(241./256, 98./256, 67./256),(241./256, 98./256, 67./256)],ecolor='k',edgecolor='none' )\n",
    "    bar([2.0,2.4,2.8,3.2],[np.mean(err2T),np.mean(err3T),np.mean(err5T),np.mean(err6T)],0.35\n",
    "        ,yerr=[[0,0,0,0],[np.std(err2T),np.std(err3T),np.std(err5T),np.std(err6T)]],color=[(73./256, 142./256, 204./256),(241./256, 98./256, 67./256),(241./256, 98./256, 67./256),(241./256, 98./256, 67./256)],ecolor='k',edgecolor='none' )\n",
    "    #customaxis(ax,size=10,lw=2)\n",
    "    ylabel('Percentage Error in Prediction',fontsize=11)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.tick_params(axis='both', direction='out')\n",
    "    ax.get_xaxis().tick_bottom()   # remove unneeded ticks\n",
    "    ax.get_yaxis().tick_left()\n",
    "\n",
    "    tick_params(\\\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off') # labels along the bottom edge are off\n",
    "\n",
    "    ylim([0,1200])\n",
    "    savefig('SSpredictionBarPlot_v2_median.pdf', bbox_inches='tight' ,dpi=100)\n",
    "    show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def intAttacks_v2(daysBetweenAttacks,plotB = 'False'):\n",
    "    from scipy.stats import nanmedian\n",
    "    num = 240\n",
    "\n",
    "    def cosa(daysBetweenAttacks):\n",
    "        ta = zeros(num)\n",
    "        tb = zeros(num)\n",
    "        for j in range(1,num+1):\n",
    "            list1 = []\n",
    "            list2 = []\n",
    "            for i in range(len(daysBetweenAttacks)-1):\n",
    "                if daysBetweenAttacks[i] <j:\n",
    "                    list1.append(daysBetweenAttacks[i+1])\n",
    "                else:\n",
    "                    list2.append(daysBetweenAttacks[i+1])\n",
    "\n",
    "            #print \"Days between \", j\n",
    "            #print len(list1),mean(list1),var(list1),median(list1)\n",
    "            #print len(list2),mean(list2),var(list2),median(list2)\n",
    "            if len(list2) > 3:\n",
    "                ta[j-1] = mean(list2)\n",
    "            else:\n",
    "                ta[j-1] = np.NaN\n",
    "            if len(list1) > 3:\n",
    "                tb[j-1] = mean(list1)\n",
    "            else:\n",
    "                tb[j-1] = np.NaN\n",
    "\n",
    "        return [ta,tb]\n",
    "\n",
    "\n",
    "    if plotB == True:\n",
    "        [ta,tb] = cosa(daysBetweenAttacks)\n",
    "        fig = figure(figsize=(4.5,3))\n",
    "        ax = subplot(1,1,1)\n",
    "        hold(True)\n",
    "        ax.plot(arange(1,num+1),ta,color=(73./256, 142./256, 204./256),linewidth=2)\n",
    "        ax.plot(arange(1,num+1),tb,color='orange',linewidth=2)\n",
    "        ax.plot(arange(1,num+1),zeros(len(ta))+mean(daysBetweenAttacks),'cyan')\n",
    "        ylabel('Time to the next attack')\n",
    "        #ylim([0,max(concatenate([ta,tb]))])\n",
    "        #xlim([1,15])\n",
    "        legend(['Mean of events without an attack in the previous i days','Mean of events with an attack in the previous i days'],3,fontsize=11,frameon=False)\n",
    "        xlabel('i = Threshold (time with/without attack)',fontsize=11)\n",
    "        customaxis(ax,size=10,lw=2)\n",
    "        print (ta-tb), ta, tb\n",
    "        xscale('log')\n",
    "\n",
    "        tempAll = np.zeros(10000)\n",
    "        tempAll2 = np.zeros(10000)\n",
    "        for i in range(10000):\n",
    "\n",
    "            tempDays = np.random.choice(daysBetweenAttacks,len(daysBetweenAttacks))\n",
    "            [_1,_2] = cosa(tempDays)\n",
    "            #ax.plot(arange(1,16),_1,color=(73./256, 142./256, 204./256),linewidth=2)\n",
    "            #ax.plot(arange(1,16),_2,color='orange',linewidth=2)\n",
    "            #ax.plot(arange(1,16),zeros(len(ta))+mean(tempDays),'cyan')\n",
    "\n",
    "            print i, nanmedian(_1-_2)\n",
    "            tempAll[i] = nanmedian(_1-_2)\n",
    "            tempAll[i] = np.nanmean(_1-_2)\n",
    "        print np.sum(tempAll>nanmedian(ta-tb))\n",
    "        print np.sum(tempAll2>nanmean(ta-tb))\n",
    "\n",
    "        title('p-values:'+str(np.sum(tempAll>nanmedian(ta-tb))/10000.)+' and '+ str(np.sum(tempAll2>nanmean(ta-tb))/10000. ))\n",
    "\n",
    "        #show()#\n",
    "        savefig('SSinteractionBetweenAttacks.pdf', bbox_inches='tight' ,dpi=100)\n",
    "        #clf()\n",
    "    return np.sum(np.abs(ta[:14]-tb[:14]))\n",
    "\n",
    "\n",
    "def fig2A():\n",
    "    [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2('ShootMiami2.csv')\n",
    "    #[ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2('everytown.csv')\n",
    "    #daysBetweenAttacks = daysBetweenAttacks[daysBet]\n",
    "    intAttacks_v2(daysBetweenAttacks,True)\n",
    "\n",
    "\n",
    "\n",
    "def fig2CD(numDays = 2, plotX=True):\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    [datesFinal,tweetsS,tweetsSS,tweetsAll,tweetsMS,tweetsMM] = studyTweets_v2()\n",
    "\n",
    "    tweetsFinal = (tweetsMS+tweetsMM)/tweetsAll\n",
    "    what = 'SS'\n",
    "    fig = figure(figsize=(4.5,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "    #fname = 'everytown.csv'\n",
    "    #fname = 'ShootMiami2.csv'\n",
    "    fname = \"USAToday.csv\"\n",
    "\n",
    "    if fname == 'ShootMiami2.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2(fname)\n",
    "    elif fname == \"USAToday.csv\": [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = studyUSAToday(fname)\n",
    "    else:   [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2(fname)\n",
    "\n",
    "    listPerc=[25,50,75]\n",
    "    j = -1\n",
    "    for threshold in percentile(daysBetweenAttacks,[25,50,75]):\n",
    "\n",
    "        print j,threshold/np.median(daysBetweenAttacks)\n",
    "\n",
    "        j+=1\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        i = 0\n",
    "        for timeD in datesFinal:\n",
    "            temp = [(date - timeD).days for date in ddd]\n",
    "            l2.append(tweetsFinal[i])\n",
    "            if filter(lambda x: x > 0 and x <= threshold,temp):\n",
    "                l1.append(1.)\n",
    "            else:\n",
    "                l1.append(0.)\n",
    "\n",
    "            i+=1\n",
    "\n",
    "\n",
    "        l1 = np.asarray(l1)\n",
    "        l2 = np.asarray(l2)\n",
    "        l1 = l1[~isnan(l2)]\n",
    "        l2 = l2[~isnan(l2)]\n",
    "        ind = np.nonzero(l1==1)[0][0]\n",
    "        l1 = l1[ind:]\n",
    "        l2 = l2[ind:]\n",
    "\n",
    "\n",
    "        l1F = []\n",
    "        l2F = []\n",
    "\n",
    "        b = percentile(l2,range(0,100,1))\n",
    "        inAnt = b[0]\n",
    "        for inPos in b[:]:\n",
    "            print(\"si\",inPos)\n",
    "            #l1F.append(np.nanmean(l1[np.nonzero(np.logical_and(l2>=inAnt,l2<inPos))[0]]))\n",
    "\n",
    "            if len(np.nonzero(l2>inAnt)[0]) > 0:\n",
    "                l1F.append(np.nanmean(l1[np.nonzero(l2>inAnt)[0]]))\n",
    "\n",
    "                l2F.append((inAnt + inPos)/2.)\n",
    "            inAnt = inPos\n",
    "\n",
    "        l1 = np.asarray(l1F)\n",
    "        l2 = np.asarray(l2F)\n",
    "\n",
    "\n",
    "\n",
    "        if numDays > 1:\n",
    "            slope1, intercept, r_value2, p_value, std_err = linregress(l2[:-1],l1[:-1])\n",
    "        else:\n",
    "            slope1, intercept, r_value2, p_value, std_err = linregress(l2[:],l1[:])\n",
    "\n",
    "\n",
    "\n",
    "        if plotX:\n",
    "            hold(True)\n",
    "            print l2\n",
    "\n",
    "            #ax.plot(l2[:-1],[threshold]*(len(l1)-1),l2[:-1]*slope1 + intercept,color='green',linewidth=3)\n",
    "            #ax.scatter(l2,[threshold]*len(l1),l1,s=60,facecolor =(73./256, 142./256, 204./256),edgecolor=(73./256, 142./256, 204./256),lw=0)\n",
    "            if what == \"SS\": ax.plot(l2[l2<100./1E6]*1E6,l1[l2<100./1E6],'-',color=((73)/256, (142.+30*j)/256, 204./256),linewidth=2,label='n = %i days' %threshold)\n",
    "            else: ax.plot(l2*1E6,l1,'-',color=((73)/256, (142.+30*j)/256, 204./256),linewidth=2,label='n = %i days' %threshold)\n",
    "            #title(tit+'. ' + 'R-value = ' +str(r_value2),fontsize=11)\n",
    "\n",
    "            #show()\n",
    "    plt.xscale('log')\n",
    "    ax.set_ylabel('Probability of attack \\nin the next n days',fontsize=12)\n",
    "    ax.set_xlabel('Average tweets containing \\n\\\\\"mass\\\" and \\\"shooting\\\" per million',fontsize=12)\n",
    "    ax.legend(frameon=False,fontsize=10)\n",
    "    customaxis(ax,size=11,lw=2)\n",
    "    xlim((np.min(l2*1E6),np.max(l2*1E6)))\n",
    "    savefig(what+fname+'linear.pdf', bbox_inches='tight' ,dpi=100)\n",
    "    show()\n",
    "    \"\"\"\n",
    "    imshow(imMatrix.T,interpolation='None',cmap=\"BrBG\",origin='lower', aspect='auto')\n",
    "    plt.clim(0,1)\n",
    "    colorbar()\n",
    "\n",
    "    #ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "    #ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "    #ax.invert_yaxis()\n",
    "    #ax.xaxis.tick_top()\n",
    "\n",
    "    ax.set_yticklabels(range(100), l2, minor=False,rotation=45)\n",
    "    ax.set_xticklabels(range(10), linspace(1./5,2.,10),minor=False)\n",
    "\n",
    "    show()\n",
    "\n",
    "    \"\"\"\n",
    "    return r_value2\n",
    "\n",
    "\n",
    "def prediction():\n",
    "    [slope2b,interceptb] = fig1EF(returnX = True)\n",
    "\n",
    "    [datesFinal,tweetsS,tweetsSS,tweetsAll,tweetsMS,tweetsMM] = studyTweets_v2()\n",
    "\n",
    "    tweetsS /= tweetsAll\n",
    "    tweetsSS /= tweetsAll\n",
    "    tweetsMS /= tweetsAll\n",
    "    tweetsMM /= tweetsAll\n",
    "\n",
    "    stateList = [\"CA\",\"AL\",\"DC\",\"FL\",\"GA\",\"IL\",\"MI\",\"NC\",\"NY\",\"OH\",\"PA\",\"SC\",\"TN\",\"TX\",\"WA\"]\n",
    "\n",
    "    j = 0\n",
    "    slope2 = slope2b\n",
    "    intercept = interceptb\n",
    "    totalAttacks= 0\n",
    "\n",
    "    err2T = []#np.empty(0)\n",
    "\n",
    "    X = [[],[],[],[],[],[]]\n",
    "    Y = []\n",
    "    for state in stateList:\n",
    "        print state\n",
    "        [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2('ShootMiami2.csv',state=state)\n",
    "        #[ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2('everytown.csv',state=state)\n",
    "        print len(ddd),len(daysBetweenAttacks)\n",
    "\n",
    "        totalAttacks += len(daysBetweenAttacks)\n",
    "        tau1 = np.log10(float(daysBetweenAttacks[0]))\n",
    "        daysTheorAdj = np.zeros(len(daysBetweenAttacks))\n",
    "\n",
    "        i = 0\n",
    "        daysTheorAdj[0] = daysBetweenAttacks[0]\n",
    "        twiiter_5_daysSS = []\n",
    "        twiiter_5_daysS = []\n",
    "        twiiter_5_daysMS = []\n",
    "        twiiter_5_daysMM = []\n",
    "        daysBA2 = []\n",
    "        daysBA = []\n",
    "        daysTh = []\n",
    "        pTime = daysBetweenAttacks[0]\n",
    "        for times in daysBetweenAttacks[1:]:\n",
    "            j+=1\n",
    "            i+=1\n",
    "            # i+1 because the daysBetweenAttacks refer\n",
    "            temp = np.asarray([(date - ddd[i+1]).days for date in datesFinal])\n",
    "            index = np.nonzero(np.logical_and(temp>-5,temp<=0))[0]\n",
    "            print index\n",
    "            if len(index) > 0:\n",
    "                ind = index\n",
    "                twiiter_5_daysSS += [np.max(tweetsSS[ind][0:5])*1E7]\n",
    "                twiiter_5_daysS += [np.max(tweetsS[ind][0:5])*1E6]\n",
    "                twiiter_5_daysMS += [np.max(tweetsMS[ind][0:5])*1E7]\n",
    "                twiiter_5_daysMM += [np.max(tweetsMM[ind][0:5])*1E7]\n",
    "\n",
    "                daysBA2.append(pTime)\n",
    "                daysBA.append(times)\n",
    "                b = (intercept + slope2*np.log10(pTime))\n",
    "                print b\n",
    "                nTime = pTime*2**(-b)\n",
    "\n",
    "                daysTh.append(float((pTime)*(2.**-((intercept+slope2*tau1)))))\n",
    "\n",
    "            daysTheorAdj[i] = float((pTime)*(2.**-((intercept+slope2*tau1))))\n",
    "            pTime = times\n",
    "        plt.clf()\n",
    "\n",
    "        plot(daysTh,label='Th')\n",
    "        plot(daysBA,label='Y')\n",
    "        plot(daysBA2,label='X')\n",
    "        plt.legend()\n",
    "        #show()\n",
    "\n",
    "        err2 = (daysBetweenAttacks - daysTheorAdj)/daysBetweenAttacks\n",
    "        err2T.append(np.median(np.abs(err2[1:])))# = np.concatenate([err2T,np.abs(err2[1:])])\n",
    "\n",
    "        X[0] += list(daysBA2)\n",
    "        X[1] += list(daysTh)\n",
    "\n",
    "\n",
    "        X[2] += list(twiiter_5_daysSS)\n",
    "        X[3] += list(twiiter_5_daysS)\n",
    "        X[4] += list(twiiter_5_daysMS)\n",
    "        X[5] += list(twiiter_5_daysMM)\n",
    "\n",
    "\n",
    "        Y += list(daysBA)\n",
    "\n",
    "\n",
    "\n",
    "    X =  np.asarray(X).T\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "    print np.shape(X)\n",
    "    print j\n",
    "    #bar([0.1,0.5,0.9],[np.median(err2T),np.median(err5T),np.median(err6T)],0.35,yerr=[[0,0,0],[np.std(err2T),np.std(err5T),np.std(err6T)]],color=[(73./256, 142./256, 204./256),(241./256, 98./256, 67./256),(241./256, 98./256, 67./256)],ecolor='k',edgecolor='none' )\n",
    "    #bar([1.6,2.0,2.4],[np.mean(err2T),np.mean(err5T),np.mean(err6T)],0.35,yerr=[[0,0,0],[np.std(err2T),np.std(err5T),np.std(err6T)]],color=[(73./256, 142./256, 204./256),(241./256, 98./256, 67./256),(241./256, 98./256, 67./256)],ecolor='k',edgecolor='none' )\n",
    "    from sklearn import datasets, svm,cross_validation, linear_model\n",
    "\n",
    "    a_train, a_test, b_train, b_test = cross_validation.train_test_split(X[:,:], Y, test_size=0.1)#, random_state=42)\n",
    "    print np.shape(a_train)\n",
    "    plt.clf()\n",
    "    for i in range(6):\n",
    "        plot(a_train[:,i])\n",
    "    plot(a_test)\n",
    "    legend(['pT','pred','SS','S','MS','MM','True'])\n",
    "    #show()\n",
    "\n",
    "    clf = linear_model.LinearRegression(normalize=True)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', clf.coef_)\n",
    "    # The mean square error\n",
    "    print(\"Residual sum of squares: %.2f\"\n",
    "          % np.mean((clf.predict(a_test) - b_test) ** 2))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % clf.score(a_test, b_test))\n",
    "\n",
    "    #clf = svm.SVC(kernel='rbf')\n",
    "    #clf.fit(a_train, b_train)\n",
    "    #Z = clf.predict(a_test)\n",
    "    print np.shape(a_test)\n",
    "    print clf.predict(a_test)\n",
    "\n",
    "    print b_test\n",
    "\n",
    "    plt.clf()\n",
    "    for i in range(6):\n",
    "        plot(a_test[:,i])\n",
    "    plot(b_test)\n",
    "    plot(clf.predict(a_test))\n",
    "    legend(['pT','pred','SS','S','MS','MM','True','Pred'])\n",
    "    #show()\n",
    "\n",
    "    print np.median(err2T)\n",
    "    print np.median(np.abs(clf.predict(a_test)-b_test)/b_test)\n",
    "    print np.median(np.abs(a_test[:,1]-b_test)/b_test)\n",
    "\n",
    "    print np.mean(err2T)\n",
    "    print np.mean(np.abs(clf.predict(a_test)-b_test)/b_test)\n",
    "    print np.mean(np.abs(a_test[:,1]-b_test)/b_test)\n",
    "    err2T = []\n",
    "    err3T = []\n",
    "    err4T = []\n",
    "    counter = 0\n",
    "    for state in stateList:\n",
    "        [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2('ShootMiami2.csv',state=state)\n",
    "        print len(ddd),len(daysBetweenAttacks)\n",
    "\n",
    "        totalAttacks += len(daysBetweenAttacks)\n",
    "        tau1 = np.log10(float(daysBetweenAttacks[0]))\n",
    "        daysTheorAdj = np.zeros(len(daysBetweenAttacks))\n",
    "\n",
    "        i = 0\n",
    "        daysTheorAdj[0] = daysBetweenAttacks[0]\n",
    "        twiiter_5_daysSS = []\n",
    "        twiiter_5_daysS = []\n",
    "        twiiter_5_daysMS = []\n",
    "        twiiter_5_daysMM = []\n",
    "        daysBA2 = []\n",
    "        daysBA = []\n",
    "        daysTh = []\n",
    "        pTime = daysBetweenAttacks[0]\n",
    "        cosa = []\n",
    "\n",
    "        for times in daysBetweenAttacks[1:]:\n",
    "            j+=1\n",
    "            i+=1\n",
    "            # i+1 because the daysBetweenAttacks refer\n",
    "            temp = np.asarray([(date - ddd[i+1]).days for date in datesFinal])\n",
    "            index = np.nonzero(np.logical_and(temp>-5,temp<=0))[0]\n",
    "            print index\n",
    "            if len(index) > 0:\n",
    "                    ind = index\n",
    "                    twiiter_5_daysSS += [np.max(tweetsSS[ind][0:5])*1E7]\n",
    "                    twiiter_5_daysS += [np.max(tweetsS[ind][0:5])*1E6]\n",
    "                    twiiter_5_daysMS += [np.max(tweetsMS[ind][0:5])*1E7]\n",
    "                    twiiter_5_daysMM += [np.max(tweetsMM[ind][0:5])*1E7]\n",
    "\n",
    "                    daysBA2.append(pTime)\n",
    "                    daysBA.append(times)\n",
    "                    b = (intercept + slope2*np.log10(pTime))\n",
    "                    print b\n",
    "                    nTime = pTime*2**(-b)\n",
    "\n",
    "                    daysTh.append(float((pTime)*(2.**-((intercept+slope2*tau1)))))\n",
    "\n",
    "            daysTheorAdj[i] = float((pTime)*(2.**-((intercept+slope2*tau1))))\n",
    "            pTime = times\n",
    "        cosa = np.abs(np.asarray(daysBA)-clf.predict(np.array([daysBA2,daysTh,twiiter_5_daysSS,twiiter_5_daysS,twiiter_5_daysMS,twiiter_5_daysMM]).T))/np.asarray(daysBA)\n",
    "        cosa2 = np.abs(np.asarray(daysBA)-np.asarray(daysTh))/np.asarray(daysBA)\n",
    "        print \"cosa\", cosa\n",
    "        err2 = (daysBetweenAttacks - daysTheorAdj)/daysBetweenAttacks\n",
    "        err2T.append(np.median(np.abs(err2[1:])))# = np.concatenate([err2T,np.abs(err2[1:])])\n",
    "\n",
    "        if len(cosa)>0:\n",
    "            counter += 1\n",
    "            print state,counter\n",
    "            print daysBA\n",
    "            print clf.predict(np.array([daysBA2,daysTh,twiiter_5_daysSS,twiiter_5_daysS,twiiter_5_daysMS,twiiter_5_daysMM]).T)\n",
    "            err3T.append(np.median(cosa))# = np.concatenate([err2T,np.abs(err2[1:])])\n",
    "            err4T.append(np.median(cosa2))# = np.concatenate([err2T,np.abs(err2[1:])])\n",
    "\n",
    "    sleep()\n",
    "    print err2T\n",
    "    print err3T\n",
    "    print err4T\n",
    "    print err3T[err3T<20]\n",
    "    err3T = np.asarray(err3T)\n",
    "    print np.median(err2T)\n",
    "    print err3T\n",
    "    print np.median(err3T[err3T<20])\n",
    "    print np.median(err4T)\n",
    "    print np.std(err2T)\n",
    "    print np.std(err3T[err3T<20])\n",
    "    print np.std(err4T)\n",
    "    print np.mean(err2T)\n",
    "    print np.nanmean(err3T[err3T<20])\n",
    "    print np.nanmean(err4T)\n",
    "    plt.clf()\n",
    "    figure(figsize=(3,3))\n",
    "    ax = subplot(1,1,1)\n",
    "\n",
    "    bar([0.1,0.5,0.9],[np.median(err2T),np.median(err3T[err3T<20]),np.median(err4T)],0.35,yerr=[[0,0,0],[np.std(err2T),np.std(err3T[err3T<20]),np.std(err4T)]],color=[(73./256, 142./256, 204./256),(241./256, 98./256, 67./256),(241./256, 98./256, 67./256)],ecolor='k',edgecolor='none' )\n",
    "    show()\n",
    "\n",
    "def marginalProbability():\n",
    "    import statsmodels.api as sm\n",
    "    for fname in ['ShootMiami2.csv']:\n",
    "        for name in [0]:#'NCollege','College',0]:\n",
    "            if fname == 'ShootMiami2.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2(fname,type=name)\n",
    "            else: [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2(fname,type=name)\n",
    "            h = 0\n",
    "            for nbins in range(4,11,1):\n",
    "                h += 1\n",
    "                bins =  np.sort(daysBetweenAttacks)[np.asarray([int(_) for _ in np.linspace(0,len(daysBetweenAttacks)-1,nbins)])]\n",
    "\n",
    "                logDays = (daysBetweenAttacks)\n",
    "\n",
    "                freqM,_,_ = np.histogram2d(logDays[:-1],logDays[1:],bins= bins)\n",
    "                freqBoth,bins = np.histogram(logDays,bins = bins)\n",
    "                #freqBoth = freqBoth/np.sum(freqBoth)\n",
    "                #freqM = freqM/np.sum(freqM)\n",
    "                print bins\n",
    "                m1 = np.sum(freqM)\n",
    "\n",
    "                marginal = []\n",
    "                both = []\n",
    "                for i in range(len(bins)-1):\n",
    "                    for j in range(len(bins)-1):\n",
    "\n",
    "                        freqM[i,j] /= (float(freqBoth[i]*freqBoth[j])/np.sum(freqBoth)**2)*m1\n",
    "                        #marginal.append(freqM[i,j])\n",
    "                        #both.append((freqBoth[i]*freqBoth[j]))\n",
    "\n",
    "                #plt.plot(both,marginal,'o')\n",
    "                #lowess = sm.nonparametric.lowess\n",
    "                #a = lowess(marginal,both,frac = 0.66,delta=0.0)\n",
    "                #plt.plot(a[:,0],a[:,1], linewidth=2,color='green')\n",
    "                plt.subplot(3,3,h)\n",
    "                plt.imshow(freqM,interpolation='none',origin='lower')\n",
    "                plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "def marginalProbability2():\n",
    "    import statsmodels.api as sm\n",
    "    for fname in ['ShootMiami2.csv']:#['everytown.csv']:#\n",
    "        for name in [0]:#'NCollege','College',0]:\n",
    "            if fname == 'ShootMiami2.csv': [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2(fname,type=name)\n",
    "            elif fname == \"USAToday.csv\": [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = studyUSAToday(fname,type=name)\n",
    "            else: [ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysEveryTown_v2(fname,type=name)\n",
    "            fig = figure(figsize=(4.5,3.))\n",
    "            ax =  fig.add_subplot(1,1,1)\n",
    "            h = 0\n",
    "            for nbins in [7]:\n",
    "                h += 1\n",
    "                bins =  np.sort(daysBetweenAttacks)[np.asarray([int(_) for _ in np.linspace(0,len(daysBetweenAttacks)-1,nbins)])]\n",
    "                bins = [int(_) for _ in bins]\n",
    "                print bins\n",
    "\n",
    "                x = []\n",
    "                y = []\n",
    "                for i in range(len(daysBetweenAttacks)-1):\n",
    "                    if daysBetweenAttacks[i] < 7 :\n",
    "                        x.append(daysBetweenAttacks[i+1])\n",
    "                    else:\n",
    "                        y.append(daysBetweenAttacks[i+1])\n",
    "                x = np.asfarray(x)\n",
    "                y = np.asfarray(y)\n",
    "\n",
    "                freqX,bins= np.histogram(x,bins=bins)\n",
    "                freqY,bins= np.histogram(y,bins=bins)\n",
    "                freqX = np.asfarray(freqX)/np.sum(freqX)\n",
    "                freqY = np.asfarray(freqY)/np.sum(freqY)\n",
    "                t = np.vstack([freqX,freqY])\n",
    "\n",
    "                plt.imshow(t,interpolation='none',origin='lower',cmap='Blues')\n",
    "                plt.colorbar(orientation='horizontal')\n",
    "                plt.xlabel('Time to next attack (Days)',fontsize=10)\n",
    "                plt.xticks(range(len(bins)-1),[str(_)+\" - \" + str(_2) for (_,_2) in zip(bins[:-1],bins[1:])],fontsize=10)\n",
    "                plt.yticks([0,1],[\"Attack in \\n previous 7 days\", \"No Attack in \\n previous 7 days\"],fontsize=10)\n",
    "\n",
    "            savefig('fig1B.pdf', bbox_inches='tight' ,dpi=10)\n",
    "            savefig('fig1B.png', bbox_inches='tight' ,dpi=10)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def main1():\n",
    "    #studyTweets_v2()\n",
    "    #testX()\n",
    "\n",
    "    fig1A() ##Pooewr-law\n",
    "    #fig1BCD() ## lowess. this\n",
    "    #fig1EF() # Regression\n",
    "    #fig1G() #Prediction\n",
    "\n",
    "\n",
    "    #residualsMiami_v2()\n",
    "    #marginalProbability()\n",
    "    #marginalProbability2() #. this\n",
    "\n",
    "    #fig2A()\n",
    "    #fig2CD()\n",
    "\n",
    "    #residualsMiami_v2()\n",
    "    #prediction()\n",
    "    #fname = 'ShootMiami2.csv'\n",
    "    #[ddd,sizeEvent,sizeEvent2,daysBetweenAttacks,cV,cV2,vtm] = regetDataDaysMiami_v2(fname)\n",
    "    #plot(daysBetweenAttacks,sizeEvent2[1:],'o')\n",
    "    #show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     main1()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
